"""
Data backup and storage management system
"""

import zipfile
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any

from discord.ext import commands, tasks

from src.bot.notification_system import NotificationCategory, NotificationLevel
from src.config.settings import get_settings
from src.obsidian.github_sync import GitHubObsidianSync
from src.utils.mixins import LoggerMixin


class BackupType(str, Enum):
    """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Çø„Ç§„Éó"""

    FULL = "full"
    INCREMENTAL = "incremental"
    OBSIDIAN_ONLY = "obsidian_only"
    CONFIG_ONLY = "config_only"


class BackupDestination(str, Enum):
    """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÖà"""

    LOCAL = "local"
    CLOUD_STORAGE = "cloud_storage"
    GITHUB = "github"


class BackupStatus(str, Enum):
    """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÁä∂ÊÖã"""

    SUCCESS = "success"
    FAILED = "failed"
    IN_PROGRESS = "in_progress"
    PARTIAL = "partial"


class DataBackupSystem(LoggerMixin):
    """„Éá„Éº„Çø„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Å®„Çπ„Éà„É¨„Éº„Ç∏ÁÆ°ÁêÜ„Ç∑„Çπ„ÉÜ„É†"""

    def __init__(
        self, bot: commands.Bot, notification_system: Any | None = None
    ) -> None:
        self.bot = bot
        self.notification_system = notification_system

        # „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóË®≠ÂÆö
        self.backup_dir = Path.cwd() / "backups"
        self.backup_dir.mkdir(exist_ok=True)

        # „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂ±•Ê≠¥
        self.backup_history: list[dict[str, Any]] = []

        # Ë®≠ÂÆö
        self.auto_backup_enabled = False
        self.backup_interval_hours = 24
        self.max_backup_files = 30
        self.backup_destinations = [BackupDestination.LOCAL]

        # settings „Ç§„É≥„Çπ„Çø„É≥„Çπ„ÇíÂèñÂæó
        settings = get_settings()

        # GitHub ÂêåÊúü„Ç∑„Çπ„ÉÜ„É†
        self.github_sync = GitHubObsidianSync()

        # „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂØæË±°„Éá„Ç£„É¨„ÇØ„Éà„É™
        self.backup_sources = {
            "obsidian_vault": settings.obsidian_vault_path,
            "config": Path.cwd() / ".config",
            "logs": Path.cwd() / "logs",
        }

        # „Çπ„Ç±„Ç∏„É•„Éº„É©„Éº„Çø„Çπ„ÇØ„ÅÆÂàùÊúüÂåñ
        self._setup_scheduled_backup()

    def _setup_scheduled_backup(self) -> None:
        """ÂÆöÊúü„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Çπ„Ç±„Ç∏„É•„Éº„É©„Éº„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó"""
        try:

            @tasks.loop(hours=self.backup_interval_hours)
            async def scheduled_backup() -> None:
                if self.auto_backup_enabled:
                    await self.run_backup(BackupType.INCREMENTAL, auto_triggered=True)

            self.scheduled_backup_task = scheduled_backup
            self.logger.info("Backup scheduler configured")

        except Exception as e:
            self.logger.error("Failed to setup backup scheduler", error=str(e))

    async def start(self) -> None:
        """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Ç∑„Çπ„ÉÜ„É†ÈñãÂßã"""
        try:
            if self.auto_backup_enabled:
                self.scheduled_backup_task.start()
                self.logger.info("Automatic backup system started")
            else:
                self.logger.info("Backup system started (manual mode)")

        except Exception as e:
            self.logger.error(
                "Failed to start backup system", error=str(e), exc_info=True
            )

    async def stop(self) -> None:
        """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Ç∑„Çπ„ÉÜ„É†ÂÅúÊ≠¢"""
        try:
            if hasattr(self, "scheduled_backup_task"):
                self.scheduled_backup_task.cancel()

            self.logger.info("Backup system stopped")

        except Exception as e:
            self.logger.error("Failed to stop backup system", error=str(e))

    async def run_backup(
        self,
        backup_type: BackupType = BackupType.FULL,
        destinations: list[BackupDestination] | None = None,
        auto_triggered: bool = False,
    ) -> dict[str, Any]:
        """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆüË°å"""
        backup_id = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        try:
            # ÈÄöÁü•ÈÄÅ‰ø°ÔºàÈñãÂßãÔºâ
            if self.notification_system and not auto_triggered:
                await self.notification_system.send_notification(
                    level=NotificationLevel.INFO,
                    category=NotificationCategory.SYSTEM_EVENTS,
                    title="üíæ „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÈñãÂßã",
                    message=f"„Éá„Éº„Çø„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÇíÈñãÂßã„Åó„Åæ„Åô ({backup_type.value})",
                    details={"backup_id": backup_id, "type": backup_type.value},
                )

            backup_destinations = destinations or self.backup_destinations
            backup_result: dict[str, Any] = {
                "backup_id": backup_id,
                "type": backup_type.value,
                "start_time": datetime.now(),
                "status": BackupStatus.IN_PROGRESS.value,
                "destinations": [dest.value for dest in backup_destinations],
                "files_backed_up": 0,
                "total_size_mb": 0,
                "errors": [],
            }

            # „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆüË°å
            if backup_type == BackupType.FULL:
                backup_result.update(await self._run_full_backup(backup_id))
            elif backup_type == BackupType.INCREMENTAL:
                backup_result.update(await self._run_incremental_backup(backup_id))
            elif backup_type == BackupType.OBSIDIAN_ONLY:
                backup_result.update(await self._run_obsidian_backup(backup_id))
            elif backup_type == BackupType.CONFIG_ONLY:
                backup_result.update(await self._run_config_backup(backup_id))

            backup_result["end_time"] = datetime.now()
            end_time = backup_result["end_time"]
            start_time = backup_result["start_time"]
            if isinstance(end_time, datetime) and isinstance(start_time, datetime):
                backup_result["duration_seconds"] = (
                    end_time - start_time
                ).total_seconds()
            else:
                backup_result["duration_seconds"] = 0.0

            # „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÖà„Å∏„ÅÆ‰øùÂ≠ò
            for destination in backup_destinations:
                try:
                    await self._save_to_destination(
                        backup_id, destination, backup_result
                    )
                except Exception as e:
                    errors = backup_result.get("errors", [])
                    if isinstance(errors, list):
                        errors.append(f"Destination {destination.value}: {str(e)}")
                        backup_result["errors"] = errors

            # ÁµêÊûúÂà§ÂÆö
            if backup_result["errors"]:
                backup_result["status"] = BackupStatus.PARTIAL.value
            else:
                backup_result["status"] = BackupStatus.SUCCESS.value

            # Â±•Ê≠¥„Å´Ë®òÈå≤
            self._record_backup(backup_result)

            # Âè§„ÅÑ„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Éï„Ç°„Ç§„É´„Çí„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
            await self._cleanup_old_backups()

            # ÈÄöÁü•ÈÄÅ‰ø°ÔºàÂÆå‰∫ÜÔºâ
            if self.notification_system:
                await self._send_backup_completion_notification(
                    backup_result, auto_triggered
                )

            self.logger.info(
                "Backup completed",
                backup_id=backup_id,
                status=backup_result["status"],
                files_count=backup_result["files_backed_up"],
                size_mb=backup_result["total_size_mb"],
            )

            return backup_result

        except Exception as e:
            error_result = {
                "backup_id": backup_id,
                "type": backup_type.value,
                "start_time": datetime.now(),
                "status": BackupStatus.FAILED.value,
                "error": str(e),
            }

            self._record_backup(error_result)

            # „Ç®„É©„ÉºÈÄöÁü•
            if self.notification_system:
                await self.notification_system.send_error_notification(
                    error_type="Backup Failed",
                    error_message=f"„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}",
                    context={"backup_id": backup_id, "type": backup_type.value},
                )

            self.logger.error(
                "Backup failed", backup_id=backup_id, error=str(e), exc_info=True
            )

            return error_result

    async def _run_full_backup(self, backup_id: str) -> dict[str, Any]:
        """„Éï„É´„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆüË°å"""
        backup_path = self.backup_dir / f"{backup_id}_full.zip"
        files_backed_up = 0
        total_size = 0

        with zipfile.ZipFile(backup_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for source_name, source_path in self.backup_sources.items():
                if source_path.exists():
                    if source_path.is_dir():
                        for file_path in source_path.rglob("*"):
                            if file_path.is_file():
                                try:
                                    arc_name = f"{source_name}/{file_path.relative_to(source_path)}"
                                    zip_file.write(file_path, arc_name)
                                    files_backed_up += 1
                                    total_size += file_path.stat().st_size
                                except Exception as e:
                                    self.logger.warning(
                                        f"Failed to backup file {file_path}: {e}"
                                    )
                    else:
                        try:
                            arc_name = f"{source_name}/{source_path.name}"
                            zip_file.write(source_path, arc_name)
                            files_backed_up += 1
                            total_size += source_path.stat().st_size
                        except Exception as e:
                            self.logger.warning(
                                f"Failed to backup file {source_path}: {e}"
                            )

        return {
            "backup_file": str(backup_path),
            "files_backed_up": files_backed_up,
            "total_size_mb": round(total_size / (1024 * 1024), 2),
        }

    async def _run_incremental_backup(self, backup_id: str) -> dict[str, Any]:
        """Â¢óÂàÜ„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆüË°å"""
        # ÂâçÂõû„ÅÆ„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÊôÇÈñì„ÇíÂèñÂæó
        last_backup_time = self._get_last_backup_time()

        backup_path = self.backup_dir / f"{backup_id}_incremental.zip"
        files_backed_up = 0
        total_size = 0

        with zipfile.ZipFile(backup_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for source_name, source_path in self.backup_sources.items():
                if source_path.exists() and source_path.is_dir():
                    for file_path in source_path.rglob("*"):
                        if file_path.is_file():
                            try:
                                # „Éï„Ç°„Ç§„É´„ÅÆÊõ¥Êñ∞ÊôÇÈñì„Çí„ÉÅ„Çß„ÉÉ„ÇØ
                                file_mtime = datetime.fromtimestamp(
                                    file_path.stat().st_mtime
                                )
                                if (
                                    last_backup_time is None
                                    or file_mtime > last_backup_time
                                ):
                                    arc_name = f"{source_name}/{file_path.relative_to(source_path)}"
                                    zip_file.write(file_path, arc_name)
                                    files_backed_up += 1
                                    total_size += file_path.stat().st_size
                            except Exception as e:
                                self.logger.warning(
                                    f"Failed to backup file {file_path}: {e}"
                                )

        return {
            "backup_file": str(backup_path),
            "files_backed_up": files_backed_up,
            "total_size_mb": round(total_size / (1024 * 1024), 2),
            "last_backup_time": (
                last_backup_time.isoformat() if last_backup_time else None
            ),
        }

    async def _run_obsidian_backup(self, backup_id: str) -> dict[str, Any]:
        """Obsidian Â∞ÇÁî®„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó"""
        backup_path = self.backup_dir / f"{backup_id}_obsidian.zip"
        files_backed_up = 0
        total_size = 0

        obsidian_path = self.backup_sources.get("obsidian_vault")
        if not obsidian_path or not obsidian_path.exists():
            return {
                "backup_file": str(backup_path),
                "files_backed_up": 0,
                "total_size_mb": 0,
                "error": "Obsidian vault path not found",
            }

        with zipfile.ZipFile(backup_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for file_path in obsidian_path.rglob("*"):
                if file_path.is_file():
                    try:
                        arc_name = str(file_path.relative_to(obsidian_path))
                        zip_file.write(file_path, arc_name)
                        files_backed_up += 1
                        total_size += file_path.stat().st_size
                    except Exception as e:
                        self.logger.warning(
                            f"Failed to backup Obsidian file {file_path}: {e}"
                        )

        return {
            "backup_file": str(backup_path),
            "files_backed_up": files_backed_up,
            "total_size_mb": round(total_size / (1024 * 1024), 2),
        }

    async def _run_config_backup(self, backup_id: str) -> dict[str, Any]:
        """Ë®≠ÂÆöÂ∞ÇÁî®„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó"""
        backup_path = self.backup_dir / f"{backup_id}_config.zip"
        files_backed_up = 0
        total_size = 0

        config_path = self.backup_sources.get("config")
        if not config_path or not config_path.exists():
            return {
                "backup_file": str(backup_path),
                "files_backed_up": 0,
                "total_size_mb": 0,
                "error": "Config path not found",
            }

        with zipfile.ZipFile(backup_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for file_path in config_path.rglob("*"):
                if file_path.is_file():
                    try:
                        arc_name = str(file_path.relative_to(config_path))
                        zip_file.write(file_path, arc_name)
                        files_backed_up += 1
                        total_size += file_path.stat().st_size
                    except Exception as e:
                        self.logger.warning(
                            f"Failed to backup config file {file_path}: {e}"
                        )

        # ËøΩÂä†Ë®≠ÂÆö„Éï„Ç°„Ç§„É´
        additional_configs = [".env", ".env.development", "pyproject.toml"]
        for config_file in additional_configs:
            config_file_path = Path.cwd() / config_file
            if config_file_path.exists():
                try:
                    zip_file.write(config_file_path, config_file)
                    files_backed_up += 1
                    total_size += config_file_path.stat().st_size
                except Exception as e:
                    self.logger.warning(
                        f"Failed to backup config file {config_file_path}: {e}"
                    )

        return {
            "backup_file": str(backup_path),
            "files_backed_up": files_backed_up,
            "total_size_mb": round(total_size / (1024 * 1024), 2),
        }

    async def _save_to_destination(
        self,
        backup_id: str,
        destination: BackupDestination,
        backup_result: dict[str, Any],
    ) -> None:
        """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÖà„Å∏„ÅÆ‰øùÂ≠ò"""
        if destination == BackupDestination.LOCAL:
            # „É≠„Éº„Ç´„É´‰øùÂ≠ò„ÅØÊó¢„Å´ÂÆå‰∫Ü
            pass
        elif destination == BackupDestination.CLOUD_STORAGE:
            # „ÇØ„É©„Ç¶„Éâ„Çπ„Éà„É¨„Éº„Ç∏„Å∏„ÅÆ‰øùÂ≠òÔºàÊú™ÂÆüË£ÖÔºâ
            self.logger.info(f"Cloud storage backup not implemented for {backup_id}")
        elif destination == BackupDestination.GITHUB:
            # GitHub „Å∏„ÅÆ‰øùÂ≠ò
            await self._save_to_github(backup_id, backup_result)

    async def restore_backup(
        self, backup_id: str, target_directory: Path | None = None
    ) -> dict[str, Any]:
        """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Åã„Çâ„ÅÆÂæ©ÂÖÉ"""
        try:
            # „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Éï„Ç°„Ç§„É´„ÇíÊ§úÁ¥¢
            backup_files = list(self.backup_dir.glob(f"{backup_id}*"))
            if not backup_files:
                return {"error": f"Backup {backup_id} not found"}

            backup_file = backup_files[0]
            restore_target = target_directory or Path.cwd() / "restore" / backup_id
            restore_target.mkdir(parents=True, exist_ok=True)

            files_restored = 0

            with zipfile.ZipFile(backup_file, "r") as zip_file:
                zip_file.extractall(restore_target)
                files_restored = len(zip_file.namelist())

            restore_result = {
                "backup_id": backup_id,
                "restore_path": str(restore_target),
                "files_restored": files_restored,
                "status": "success",
                "timestamp": datetime.now().isoformat(),
            }

            self.logger.info(
                "Backup restored",
                backup_id=backup_id,
                files_restored=files_restored,
                restore_path=str(restore_target),
            )

            return restore_result

        except Exception as e:
            self.logger.error(f"Backup restore failed: {e}", exc_info=True)
            return {"error": str(e)}

    async def _cleanup_old_backups(self) -> None:
        """Âè§„ÅÑ„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Éï„Ç°„Ç§„É´„ÅÆ„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó"""
        try:
            backup_files = sorted(
                self.backup_dir.glob("backup_*.zip"),
                key=lambda f: f.stat().st_mtime,
                reverse=True,
            )

            if len(backup_files) > self.max_backup_files:
                files_to_remove = backup_files[self.max_backup_files :]
                for file_to_remove in files_to_remove:
                    try:
                        file_to_remove.unlink()
                        self.logger.info(f"Removed old backup: {file_to_remove.name}")
                    except Exception as e:
                        self.logger.warning(
                            f"Failed to remove old backup {file_to_remove}: {e}"
                        )

        except Exception as e:
            self.logger.error(f"Backup cleanup failed: {e}")

    def _get_last_backup_time(self) -> datetime | None:
        """ÊúÄÂæå„ÅÆ„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÊôÇÈñì„ÇíÂèñÂæó"""
        if not self.backup_history:
            return None

        successful_backups = [
            backup
            for backup in self.backup_history
            if backup.get("status") == BackupStatus.SUCCESS.value
        ]

        if not successful_backups:
            return None

        last_backup = max(successful_backups, key=lambda x: x["start_time"])
        start_time = last_backup["start_time"]
        if isinstance(start_time, datetime):
            return start_time
        if isinstance(start_time, str):
            return datetime.fromisoformat(start_time)
        return None

    async def _send_backup_completion_notification(
        self, backup_result: dict[str, Any], auto_triggered: bool
    ) -> None:
        """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆå‰∫ÜÈÄöÁü•"""
        if auto_triggered and backup_result["status"] == BackupStatus.SUCCESS.value:
            # Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÅåÊàêÂäü„Åó„ÅüÂ†¥Âêà„ÅØË©≥Á¥∞ÈÄöÁü•„Çí„Çπ„Ç≠„ÉÉ„Éó
            return

        if not self.notification_system:
            return

        if backup_result["status"] == BackupStatus.SUCCESS.value:
            title = "‚úÖ „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂÆå‰∫Ü"
            message = "„Éá„Éº„Çø„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÅåÊ≠£Â∏∏„Å´ÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ"
            level = NotificationLevel.SUCCESS
        elif backup_result["status"] == BackupStatus.PARTIAL.value:
            title = "‚ö†Ô∏è „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÈÉ®ÂàÜÂÆå‰∫Ü"
            message = "„Éá„Éº„Çø„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÅåÈÉ®ÂàÜÁöÑ„Å´ÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºà‰∏ÄÈÉ®„Ç®„É©„Éº„ÅÇ„ÇäÔºâ„ÄÇ"
            level = NotificationLevel.WARNING
        else:
            title = "‚ùå „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂ§±Êïó"
            message = "„Éá„Éº„Çø„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ"
            level = NotificationLevel.ERROR

        embed_fields = [
            {
                "name": "üìä Áµ±Ë®àÊÉÖÂ†±",
                "value": (
                    f"„Éï„Ç°„Ç§„É´Êï∞: {backup_result.get('files_backed_up', 0)}‰ª∂\n"
                    f"„Çµ„Ç§„Ç∫: {backup_result.get('total_size_mb', 0)}MB\n"
                    f"ÊâÄË¶ÅÊôÇÈñì: {backup_result.get('duration_seconds', 0):.1f}Áßí"
                ),
                "inline": False,
            }
        ]

        if backup_result.get("errors"):
            embed_fields.append(
                {
                    "name": "‚ö†Ô∏è „Ç®„É©„ÉºË©≥Á¥∞",
                    "value": "\n".join(backup_result["errors"][:3]),
                    "inline": False,
                }
            )

        await self.notification_system.send_notification(
            level=level,
            category=NotificationCategory.SYSTEM_EVENTS,
            title=title,
            message=message,
            details=backup_result,
            embed_fields=embed_fields,
        )

    def _record_backup(self, backup_result: dict[str, Any]) -> None:
        """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂ±•Ê≠¥Ë®òÈå≤"""
        # datetime „Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÇíÊñáÂ≠óÂàó„Å´Â§âÊèõ
        serializable_result = backup_result.copy()
        for key in ["start_time", "end_time"]:
            if key in serializable_result and isinstance(
                serializable_result[key], datetime
            ):
                serializable_result[key] = serializable_result[key].isoformat()

        self.backup_history.append(serializable_result)

    async def _save_to_github(
        self, backup_id: str, backup_result: dict[str, Any]
    ) -> None:
        """GitHub „Å∏„ÅÆ‰øùÂ≠ò"""
        try:
            commit_message = (
                f"Backup: {backup_id} - {backup_result.get('files_backed_up', 0)} files"
            )
            success = await self.github_sync.sync_to_github(commit_message)

            if success:
                self.logger.info(f"Successfully saved backup {backup_id} to GitHub")
            else:
                self.logger.warning(f"Failed to save backup {backup_id} to GitHub")

        except Exception as e:
            self.logger.error(f"GitHub backup failed for {backup_id}: {e}")
            raise

        # Â±•Ê≠¥„Çµ„Ç§„Ç∫Âà∂Èôê
        if len(self.backup_history) > 50:
            self.backup_history = self.backup_history[-50:]

    def get_backup_status(self) -> dict[str, Any]:
        """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Ç∑„Çπ„ÉÜ„É†„ÅÆÁä∂ÊÖãÂèñÂæó"""
        try:
            recent_backups = self.backup_history[-5:] if self.backup_history else []
            successful_backups = len(
                [
                    b
                    for b in self.backup_history
                    if b.get("status") == BackupStatus.SUCCESS.value
                ]
            )

            backup_files = list(self.backup_dir.glob("backup_*.zip"))
            total_backup_size = sum([f.stat().st_size for f in backup_files]) / (
                1024 * 1024
            )

            return {
                "auto_backup_enabled": self.auto_backup_enabled,
                "backup_interval_hours": self.backup_interval_hours,
                "total_backups": len(self.backup_history),
                "successful_backups": successful_backups,
                "recent_backups": recent_backups,
                "backup_files_count": len(backup_files),
                "total_backup_size_mb": round(total_backup_size, 2),
                "last_backup": self.backup_history[-1] if self.backup_history else None,
                "backup_destinations": [
                    dest.value for dest in self.backup_destinations
                ],
            }

        except Exception as e:
            self.logger.error("Failed to get backup status", error=str(e))
            return {"error": "„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÁä∂ÊÖã„ÅÆÂèñÂæó„Å´Â§±Êïó„Åó„Åæ„Åó„Åü"}

    def get_backup_history(self, limit: int = 20) -> list[dict[str, Any]]:
        """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂ±•Ê≠¥ÂèñÂæó"""
        return self.backup_history[-limit:] if self.backup_history else []

    async def configure_backup(self, config: dict[str, Any]) -> bool:
        """„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóË®≠ÂÆöÊõ¥Êñ∞"""
        try:
            if "auto_backup_enabled" in config:
                old_enabled = self.auto_backup_enabled
                self.auto_backup_enabled = config["auto_backup_enabled"]

                # Ëá™Âãï„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÅÆ„Çπ„Çø„Éº„Éà/„Çπ„Éà„ÉÉ„Éó
                if self.auto_backup_enabled and not old_enabled:
                    self.scheduled_backup_task.start()
                elif not self.auto_backup_enabled and old_enabled:
                    self.scheduled_backup_task.cancel()

            if "backup_interval_hours" in config:
                self.backup_interval_hours = max(
                    1, int(config["backup_interval_hours"])
                )
                # „Çø„Çπ„ÇØ„ÇíÂÜçËµ∑Âãï
                if self.auto_backup_enabled:
                    self.scheduled_backup_task.cancel()
                    self._setup_scheduled_backup()
                    self.scheduled_backup_task.start()

            if "max_backup_files" in config:
                self.max_backup_files = max(1, int(config["max_backup_files"]))

            self.logger.info("Backup configuration updated", config=config)
            return True

        except Exception as e:
            self.logger.error("Failed to configure backup", error=str(e))
            return False
