"""
Data backup and storage management system
"""

import zipfile
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any

from discord.ext import commands, tasks

from src.bot.notification_system import NotificationCategory, NotificationLevel
from src.config.settings import get_settings
from src.obsidian.github_sync import GitHubObsidianSync
from src.utils.mixins import LoggerMixin


class BackupType(str, Enum):
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ—"""

    FULL = "full"
    INCREMENTAL = "incremental"
    OBSIDIAN_ONLY = "obsidian_only"
    CONFIG_ONLY = "config_only"


class BackupDestination(str, Enum):
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å…ˆ"""

    LOCAL = "local"
    CLOUD_STORAGE = "cloud_storage"
    GITHUB = "github"


class BackupStatus(str, Enum):
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çŠ¶æ…‹"""

    SUCCESS = "success"
    FAILED = "failed"
    IN_PROGRESS = "in_progress"
    PARTIAL = "partial"


class DataBackupSystem(LoggerMixin):
    """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(
        self, bot: commands.Bot, notification_system: Any | None = None
    ) -> None:
        self.bot = bot
        self.notification_system = notification_system

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š
        self.backup_dir = Path.cwd() / "backups"
        self.backup_dir.mkdir(exist_ok=True)

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å±¥æ­´
        self.backup_history: list[dict[str, Any]] = []

        # è¨­å®š
        self.auto_backup_enabled = False
        self.backup_interval_hours = 24
        self.max_backup_files = 30
        self.backup_destinations = [BackupDestination.LOCAL]

        # settings ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
        settings = get_settings()

        # GitHub åŒæœŸã‚·ã‚¹ãƒ†ãƒ 
        self.github_sync = GitHubObsidianSync()

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.backup_sources = {
            "obsidian_vault": settings.obsidian_vault_path,
            "config": Path.cwd() / ".config",
            "logs": Path.cwd() / "logs",
        }

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¿ã‚¹ã‚¯ã®åˆæœŸåŒ–
        self._setup_scheduled_backup()

    def _setup_scheduled_backup(self) -> None:
        """å®šæœŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        try:

            @tasks.loop(hours=self.backup_interval_hours)
            async def scheduled_backup() -> None:
                if self.auto_backup_enabled:
                    await self.run_backup(BackupType.INCREMENTAL, auto_triggered=True)

            self.scheduled_backup_task = scheduled_backup
            self.logger.info("Backup scheduler configured")

        except Exception as e:
            self.logger.error("Failed to setup backup scheduler", error=str(e))

    async def start(self) -> None:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹"""
        try:
            if self.auto_backup_enabled:
                self.scheduled_backup_task.start()
                self.logger.info("Automatic backup system started")
            else:
                self.logger.info("Backup system started (manual mode)")

        except Exception as e:
            self.logger.error(
                "Failed to start backup system", error=str(e), exc_info=True
            )

    async def stop(self) -> None:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ åœæ­¢"""
        try:
            if hasattr(self, "scheduled_backup_task"):
                self.scheduled_backup_task.cancel()

            self.logger.info("Backup system stopped")

        except Exception as e:
            self.logger.error("Failed to stop backup system", error=str(e))

    async def run_backup(
        self,
        backup_type: BackupType = BackupType.FULL,
        destinations: list[BackupDestination] | None = None,
        auto_triggered: bool = False,
    ) -> dict[str, Any]:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ"""
        backup_id = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        try:
            # é€šçŸ¥é€ä¿¡ï¼ˆé–‹å§‹ï¼‰
            if self.notification_system and not auto_triggered:
                await self.notification_system.send_notification(
                    level=NotificationLevel.INFO,
                    category=NotificationCategory.SYSTEM_EVENTS,
                    title="ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹",
                    message=f"ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹ã—ã¾ã™ ({backup_type.value})",
                    details={"backup_id": backup_id, "type": backup_type.value},
                )

            backup_destinations = destinations or self.backup_destinations
            backup_result: dict[str, Any] = {
                "backup_id": backup_id,
                "type": backup_type.value,
                "start_time": datetime.now(),
                "status": BackupStatus.IN_PROGRESS.value,
                "destinations": [dest.value for dest in backup_destinations],
                "files_backed_up": 0,
                "total_size_mb": 0,
                "errors": [],
            }

            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
            if backup_type == BackupType.FULL:
                backup_result.update(await self._run_full_backup(backup_id))
            elif backup_type == BackupType.INCREMENTAL:
                backup_result.update(await self._run_incremental_backup(backup_id))
            elif backup_type == BackupType.OBSIDIAN_ONLY:
                backup_result.update(await self._run_obsidian_backup(backup_id))
            elif backup_type == BackupType.CONFIG_ONLY:
                backup_result.update(await self._run_config_backup(backup_id))

            backup_result["end_time"] = datetime.now()
            end_time = backup_result["end_time"]
            start_time = backup_result["start_time"]
            if isinstance(end_time, datetime) and isinstance(start_time, datetime):
                backup_result["duration_seconds"] = (
                    end_time - start_time
                ).total_seconds()
            else:
                backup_result["duration_seconds"] = 0.0

            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å…ˆã¸ã®ä¿å­˜
            for destination in backup_destinations:
                try:
                    await self._save_to_destination(
                        backup_id, destination, backup_result
                    )
                except Exception as e:
                    errors = backup_result.get("errors", [])
                    if isinstance(errors, list):
                        errors.append(f"Destination {destination.value}: {str(e)}")
                        backup_result["errors"] = errors

            # çµæœåˆ¤å®š
            if backup_result["errors"]:
                backup_result["status"] = BackupStatus.PARTIAL.value
            else:
                backup_result["status"] = BackupStatus.SUCCESS.value

            # å±¥æ­´ã«è¨˜éŒ²
            self._record_backup(backup_result)

            # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            await self._cleanup_old_backups()

            # é€šçŸ¥é€ä¿¡ï¼ˆå®Œäº†ï¼‰
            if self.notification_system:
                await self._send_backup_completion_notification(
                    backup_result, auto_triggered
                )

            self.logger.info(
                "Backup completed",
                backup_id=backup_id,
                status=backup_result["status"],
                files_count=backup_result["files_backed_up"],
                size_mb=backup_result["total_size_mb"],
            )

            return backup_result

        except Exception as e:
            error_result = {
                "backup_id": backup_id,
                "type": backup_type.value,
                "start_time": datetime.now(),
                "status": BackupStatus.FAILED.value,
                "error": str(e),
            }

            self._record_backup(error_result)

            # ã‚¨ãƒ©ãƒ¼é€šçŸ¥
            if self.notification_system:
                await self.notification_system.send_error_notification(
                    error_type="Backup Failed",
                    error_message=f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}",
                    context={"backup_id": backup_id, "type": backup_type.value},
                )

            self.logger.error(
                "Backup failed", backup_id=backup_id, error=str(e), exc_info=True
            )

            return error_result

    async def _run_full_backup(self, backup_id: str) -> dict[str, Any]:
        """ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ"""
        backup_path = self.backup_dir / f"{backup_id}_full.zip"
        files_backed_up = 0
        total_size = 0

        with zipfile.ZipFile(backup_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for source_name, source_path in self.backup_sources.items():
                if source_path.exists():
                    if source_path.is_dir():
                        for file_path in source_path.rglob("*"):
                            if file_path.is_file():
                                try:
                                    arc_name = f"{source_name}/{file_path.relative_to(source_path)}"
                                    zip_file.write(file_path, arc_name)
                                    files_backed_up += 1
                                    total_size += file_path.stat().st_size
                                except Exception as e:
                                    self.logger.warning(
                                        f"Failed to backup file {file_path}: {e}"
                                    )
                    else:
                        try:
                            arc_name = f"{source_name}/{source_path.name}"
                            zip_file.write(source_path, arc_name)
                            files_backed_up += 1
                            total_size += source_path.stat().st_size
                        except Exception as e:
                            self.logger.warning(
                                f"Failed to backup file {source_path}: {e}"
                            )

        return {
            "backup_file": str(backup_path),
            "files_backed_up": files_backed_up,
            "total_size_mb": round(total_size / (1024 * 1024), 2),
        }

    async def _run_incremental_backup(self, backup_id: str) -> dict[str, Any]:
        """å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ"""
        # å‰å›ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ™‚é–“ã‚’å–å¾—
        last_backup_time = self._get_last_backup_time()

        backup_path = self.backup_dir / f"{backup_id}_incremental.zip"
        files_backed_up = 0
        total_size = 0

        with zipfile.ZipFile(backup_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for source_name, source_path in self.backup_sources.items():
                if source_path.exists() and source_path.is_dir():
                    for file_path in source_path.rglob("*"):
                        if file_path.is_file():
                            try:
                                # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ™‚é–“ã‚’ãƒã‚§ãƒƒã‚¯
                                file_mtime = datetime.fromtimestamp(
                                    file_path.stat().st_mtime
                                )
                                if (
                                    last_backup_time is None
                                    or file_mtime > last_backup_time
                                ):
                                    arc_name = f"{source_name}/{file_path.relative_to(source_path)}"
                                    zip_file.write(file_path, arc_name)
                                    files_backed_up += 1
                                    total_size += file_path.stat().st_size
                            except Exception as e:
                                self.logger.warning(
                                    f"Failed to backup file {file_path}: {e}"
                                )

        return {
            "backup_file": str(backup_path),
            "files_backed_up": files_backed_up,
            "total_size_mb": round(total_size / (1024 * 1024), 2),
            "last_backup_time": (
                last_backup_time.isoformat() if last_backup_time else None
            ),
        }

    async def _run_obsidian_backup(self, backup_id: str) -> dict[str, Any]:
        """Obsidian å°‚ç”¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        backup_path = self.backup_dir / f"{backup_id}_obsidian.zip"
        files_backed_up = 0
        total_size = 0

        obsidian_path = self.backup_sources.get("obsidian_vault")
        if not obsidian_path or not obsidian_path.exists():
            return {
                "backup_file": str(backup_path),
                "files_backed_up": 0,
                "total_size_mb": 0,
                "error": "Obsidian vault path not found",
            }

        with zipfile.ZipFile(backup_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for file_path in obsidian_path.rglob("*"):
                if file_path.is_file():
                    try:
                        arc_name = str(file_path.relative_to(obsidian_path))
                        zip_file.write(file_path, arc_name)
                        files_backed_up += 1
                        total_size += file_path.stat().st_size
                    except Exception as e:
                        self.logger.warning(
                            f"Failed to backup Obsidian file {file_path}: {e}"
                        )

        return {
            "backup_file": str(backup_path),
            "files_backed_up": files_backed_up,
            "total_size_mb": round(total_size / (1024 * 1024), 2),
        }

    async def _run_config_backup(self, backup_id: str) -> dict[str, Any]:
        """è¨­å®šå°‚ç”¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        backup_path = self.backup_dir / f"{backup_id}_config.zip"
        files_backed_up = 0
        total_size = 0

        config_path = self.backup_sources.get("config")
        if not config_path or not config_path.exists():
            return {
                "backup_file": str(backup_path),
                "files_backed_up": 0,
                "total_size_mb": 0,
                "error": "Config path not found",
            }

        with zipfile.ZipFile(backup_path, "w", zipfile.ZIP_DEFLATED) as zip_file:
            for file_path in config_path.rglob("*"):
                if file_path.is_file():
                    try:
                        arc_name = str(file_path.relative_to(config_path))
                        zip_file.write(file_path, arc_name)
                        files_backed_up += 1
                        total_size += file_path.stat().st_size
                    except Exception as e:
                        self.logger.warning(
                            f"Failed to backup config file {file_path}: {e}"
                        )

        # è¿½åŠ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
        additional_configs = [".env", ".env.development", "pyproject.toml"]
        for config_file in additional_configs:
            config_file_path = Path.cwd() / config_file
            if config_file_path.exists():
                try:
                    zip_file.write(config_file_path, config_file)
                    files_backed_up += 1
                    total_size += config_file_path.stat().st_size
                except Exception as e:
                    self.logger.warning(
                        f"Failed to backup config file {config_file_path}: {e}"
                    )

        return {
            "backup_file": str(backup_path),
            "files_backed_up": files_backed_up,
            "total_size_mb": round(total_size / (1024 * 1024), 2),
        }

    async def _save_to_destination(
        self,
        backup_id: str,
        destination: BackupDestination,
        backup_result: dict[str, Any],
    ) -> None:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å…ˆã¸ã®ä¿å­˜"""
        if destination == BackupDestination.LOCAL:
            # ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ã¯æ—¢ã«å®Œäº†
            pass
        elif destination == BackupDestination.CLOUD_STORAGE:
            # ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¸ã®ä¿å­˜ï¼ˆæœªå®Ÿè£…ï¼‰
            self.logger.info(f"Cloud storage backup not implemented for {backup_id}")
        elif destination == BackupDestination.GITHUB:
            # GitHub ã¸ã®ä¿å­˜
            await self._save_to_github(backup_id, backup_result)

    async def restore_backup(
        self, backup_id: str, target_directory: Path | None = None
    ) -> dict[str, Any]:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒ"""
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            backup_files = list(self.backup_dir.glob(f"{backup_id}*"))
            if not backup_files:
                return {"error": f"Backup {backup_id} not found"}

            backup_file = backup_files[0]
            restore_target = target_directory or Path.cwd() / "restore" / backup_id
            restore_target.mkdir(parents=True, exist_ok=True)

            files_restored = 0

            with zipfile.ZipFile(backup_file, "r") as zip_file:
                zip_file.extractall(restore_target)
                files_restored = len(zip_file.namelist())

            restore_result = {
                "backup_id": backup_id,
                "restore_path": str(restore_target),
                "files_restored": files_restored,
                "status": "success",
                "timestamp": datetime.now().isoformat(),
            }

            self.logger.info(
                "Backup restored",
                backup_id=backup_id,
                files_restored=files_restored,
                restore_path=str(restore_target),
            )

            return restore_result

        except Exception as e:
            self.logger.error(f"Backup restore failed: {e}", exc_info=True)
            return {"error": str(e)}

    async def _cleanup_old_backups(self) -> None:
        """å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            backup_files = sorted(
                self.backup_dir.glob("backup_*.zip"),
                key=lambda f: f.stat().st_mtime,
                reverse=True,
            )

            if len(backup_files) > self.max_backup_files:
                files_to_remove = backup_files[self.max_backup_files :]
                for file_to_remove in files_to_remove:
                    try:
                        file_to_remove.unlink()
                        self.logger.info(f"Removed old backup: {file_to_remove.name}")
                    except Exception as e:
                        self.logger.warning(
                            f"Failed to remove old backup {file_to_remove}: {e}"
                        )

        except Exception as e:
            self.logger.error(f"Backup cleanup failed: {e}")

    def _get_last_backup_time(self) -> datetime | None:
        """æœ€å¾Œã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ™‚é–“ã‚’å–å¾—"""
        if not self.backup_history:
            return None

        successful_backups = [
            backup
            for backup in self.backup_history
            if backup.get("status") == BackupStatus.SUCCESS.value
        ]

        if not successful_backups:
            return None

        last_backup = max(successful_backups, key=lambda x: x["start_time"])
        start_time = last_backup["start_time"]
        if isinstance(start_time, datetime):
            return start_time
        if isinstance(start_time, str):
            return datetime.fromisoformat(start_time)
        return None

    async def _send_backup_completion_notification(
        self, backup_result: dict[str, Any], auto_triggered: bool
    ) -> None:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†é€šçŸ¥"""
        if auto_triggered and backup_result["status"] == BackupStatus.SUCCESS.value:
            # è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒæˆåŠŸã—ãŸå ´åˆã¯è©³ç´°é€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—
            return

        if not self.notification_system:
            return

        if backup_result["status"] == BackupStatus.SUCCESS.value:
            title = "âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†"
            message = "ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚"
            level = NotificationLevel.SUCCESS
        elif backup_result["status"] == BackupStatus.PARTIAL.value:
            title = "âš ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—éƒ¨åˆ†å®Œäº†"
            message = "ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒéƒ¨åˆ†çš„ã«å®Œäº†ã—ã¾ã—ãŸï¼ˆä¸€éƒ¨ã‚¨ãƒ©ãƒ¼ã‚ã‚Šï¼‰ã€‚"
            level = NotificationLevel.WARNING
        else:
            title = "âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—"
            message = "ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
            level = NotificationLevel.ERROR

        embed_fields = [
            {
                "name": "ğŸ“Š çµ±è¨ˆæƒ…å ±",
                "value": (
                    f"ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {backup_result.get('files_backed_up', 0)}ä»¶\n"
                    f"ã‚µã‚¤ã‚º: {backup_result.get('total_size_mb', 0)}MB\n"
                    f"æ‰€è¦æ™‚é–“: {backup_result.get('duration_seconds', 0):.1f}ç§’"
                ),
                "inline": False,
            }
        ]

        if backup_result.get("errors"):
            embed_fields.append(
                {
                    "name": "âš ï¸ ã‚¨ãƒ©ãƒ¼è©³ç´°",
                    "value": "\n".join(backup_result["errors"][:3]),
                    "inline": False,
                }
            )

        await self.notification_system.send_notification(
            level=level,
            category=NotificationCategory.SYSTEM_EVENTS,
            title=title,
            message=message,
            details=backup_result,
            embed_fields=embed_fields,
        )

    def _record_backup(self, backup_result: dict[str, Any]) -> None:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å±¥æ­´è¨˜éŒ²"""
        # datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        serializable_result = backup_result.copy()
        for key in ["start_time", "end_time"]:
            if key in serializable_result and isinstance(
                serializable_result[key], datetime
            ):
                serializable_result[key] = serializable_result[key].isoformat()

        self.backup_history.append(serializable_result)

    async def _save_to_github(
        self, backup_id: str, backup_result: dict[str, Any]
    ) -> None:
        """GitHub ã¸ã®ä¿å­˜"""
        try:
            commit_message = (
                f"Backup: {backup_id} - {backup_result.get('files_backed_up', 0)} files"
            )
            success = await self.github_sync.sync_to_github(commit_message)

            if success:
                self.logger.info(f"Successfully saved backup {backup_id} to GitHub")
            else:
                self.logger.warning(f"Failed to save backup {backup_id} to GitHub")

        except Exception as e:
            self.logger.error(f"GitHub backup failed for {backup_id}: {e}")
            raise

        # å±¥æ­´ã‚µã‚¤ã‚ºåˆ¶é™
        if len(self.backup_history) > 50:
            self.backup_history = self.backup_history[-50:]

    def get_backup_status(self) -> dict[str, Any]:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹å–å¾—"""
        try:
            recent_backups = self.backup_history[-5:] if self.backup_history else []
            successful_backups = len(
                [
                    b
                    for b in self.backup_history
                    if b.get("status") == BackupStatus.SUCCESS.value
                ]
            )

            backup_files = list(self.backup_dir.glob("backup_*.zip"))
            total_backup_size = sum([f.stat().st_size for f in backup_files]) / (
                1024 * 1024
            )

            return {
                "auto_backup_enabled": self.auto_backup_enabled,
                "backup_interval_hours": self.backup_interval_hours,
                "total_backups": len(self.backup_history),
                "successful_backups": successful_backups,
                "recent_backups": recent_backups,
                "backup_files_count": len(backup_files),
                "total_backup_size_mb": round(total_backup_size, 2),
                "last_backup": self.backup_history[-1] if self.backup_history else None,
                "backup_destinations": [
                    dest.value for dest in self.backup_destinations
                ],
            }

        except Exception as e:
            self.logger.error("Failed to get backup status", error=str(e))
            return {"error": "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çŠ¶æ…‹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ"}

    def get_backup_history(self, limit: int = 20) -> list[dict[str, Any]]:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å±¥æ­´å–å¾—"""
        return self.backup_history[-limit:] if self.backup_history else []

    async def configure_backup(self, config: dict[str, Any]) -> bool:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®šæ›´æ–°"""
        try:
            if "auto_backup_enabled" in config:
                old_enabled = self.auto_backup_enabled
                self.auto_backup_enabled = config["auto_backup_enabled"]

                # è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ã‚¹ã‚¿ãƒ¼ãƒˆ/ã‚¹ãƒˆãƒƒãƒ—
                if self.auto_backup_enabled and not old_enabled:
                    self.scheduled_backup_task.start()
                elif not self.auto_backup_enabled and old_enabled:
                    self.scheduled_backup_task.cancel()

            if "backup_interval_hours" in config:
                self.backup_interval_hours = max(
                    1, int(config["backup_interval_hours"])
                )
                # ã‚¿ã‚¹ã‚¯ã‚’å†èµ·å‹•
                if self.auto_backup_enabled:
                    self.scheduled_backup_task.cancel()
                    self._setup_scheduled_backup()
                    self.scheduled_backup_task.start()

            if "max_backup_files" in config:
                self.max_backup_files = max(1, int(config["max_backup_files"]))

            self.logger.info("Backup configuration updated", config=config)
            return True

        except Exception as e:
            self.logger.error("Failed to configure backup", error=str(e))
            return False
