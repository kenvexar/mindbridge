"""Note creation and Obsidian integration handler."""

import re
from typing import Any

from src.utils.mixins import LoggerMixin


class NoteHandler(LoggerMixin):
    """ãƒãƒ¼ãƒˆä½œæˆã¨ Obsidian é€£æºå°‚ç”¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""

    def __init__(
        self,
        obsidian_manager=None,
        note_template=None,
        daily_integration=None,
        template_engine=None,
        note_analyzer=None,
    ):
        self.obsidian_manager = obsidian_manager
        self.note_template = note_template
        self.daily_integration = daily_integration
        self.template_engine = template_engine
        self.note_analyzer = note_analyzer

    async def handle_obsidian_note_creation(
        self,
        message_data: dict[str, Any],
        channel_info: Any,
        ai_result: Any,
        original_message: Any = None,
    ) -> dict[str, Any]:
        """Obsidian ãƒãƒ¼ãƒˆä½œæˆå‡¦ç†"""
        try:
            import base64
            import os
            from datetime import datetime, timedelta, timezone
            from pathlib import Path

            import aiofiles
            import aiohttp

            from src.obsidian.template_system.yaml_generator import (
                YAMLFrontmatterGenerator,
            )

            # æ—¥æœ¬æ™‚é–“ã§çµ±ä¸€å‡¦ç†
            jst = timezone(timedelta(hours=9))
            now_jst = datetime.now(jst)
            timestamp = now_jst.strftime("%Y-%m-%d-%H%M%S")

            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‚’å–å¾—
            raw_content = (
                message_data.get("metadata", {})
                .get("content", {})
                .get("raw_content", "æ–°ã—ã„ãƒ¡ãƒ¢")
            )

            # Integrate audio data if available (centralized management)
            content_info = message_data.get("metadata", {}).get("content", {})
            audio_data = content_info.get("audio_transcription_data")

            if audio_data and "ğŸ¤ éŸ³å£°æ–‡å­—èµ·ã“ã—" not in raw_content:
                # Add audio section
                audio_section = (
                    f"\n\n## ğŸ¤ éŸ³å£°æ–‡å­—èµ·ã“ã—\n\n{audio_data['transcript']}"
                )
                if audio_data.get("confidence", 0) > 0.0:
                    audio_section += f"\n\n**ä¿¡é ¼åº¦**: {audio_data['confidence']:.2f} ({audio_data['confidence_level']})"
                if audio_data.get("fallback_used"):
                    audio_section += f"\n\n**æ³¨æ„**: {audio_data['fallback_reason']}"
                    if audio_data.get("saved_file_path"):
                        audio_section += (
                            f"\n**ä¿å­˜å…ˆ**: `{audio_data['saved_file_path']}`"
                        )

                raw_content += audio_section

            # Inline duplicate removal (reliable operation)
            content = raw_content
            audio_marker = "## ğŸ¤ éŸ³å£°æ–‡å­—èµ·ã“ã—"
            audio_count_before = content.count(audio_marker)

            if audio_count_before > 1:
                # ã‚·ãƒ³ãƒ—ãƒ«ãªæ–‡å­—åˆ—ç½®æ›ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
                lines = content.split("\n")
                result_lines = []
                audio_section_encountered = False
                skip_mode = False

                for line in lines:
                    if line.strip() == audio_marker.strip():
                        if not audio_section_encountered:
                            # First audio section - keep
                            audio_section_encountered = True
                            result_lines.append(line)
                        else:
                            # Duplicate audio section - start skipping
                            skip_mode = True
                            continue
                    elif line.startswith("##") and skip_mode:
                        # æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå§‹ã¾ã£ãŸã‚‰ã‚¹ã‚­ãƒƒãƒ—çµ‚äº†
                        skip_mode = False
                        result_lines.append(line)
                    elif not skip_mode:
                        # ã‚¹ã‚­ãƒƒãƒ—ãƒ¢ãƒ¼ãƒ‰ã§ãªã„å ´åˆã¯è¿½åŠ 
                        result_lines.append(line)

                content = "\n".join(result_lines)

            title_preview = self._generate_title_preview(content, audio_data)

            # AI åˆ†æã«åŸºã¥ãã‚«ãƒ†ã‚´ãƒªæ±ºå®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
            category = "memo"
            category_folder = "00_Inbox"
            if ai_result and ai_result.category:
                cat_val = ai_result.category.category.value
                if "task" in cat_val.lower() or "ã‚¿ã‚¹ã‚¯" in cat_val:
                    category = "task"
                    category_folder = "02_Tasks"
                elif (
                    "finance" in cat_val.lower()
                    or "é‡‘è" in cat_val
                    or "ãŠé‡‘" in cat_val
                ):
                    category = "finance"
                    category_folder = "20_Finance"
                elif "health" in cat_val.lower() or "å¥åº·" in cat_val:
                    category = "health"
                    category_folder = "21_Health"
                elif "idea" in cat_val.lower() or "ã‚¢ã‚¤ãƒ‡ã‚¢" in cat_val:
                    category = "idea"
                    category_folder = "03_Ideas"
                elif (
                    "knowledge" in cat_val.lower()
                    or "å­¦ç¿’" in cat_val
                    or "çŸ¥è­˜" in cat_val
                ):
                    category = "knowledge"
                    category_folder = "10_Knowledge"
                elif "project" in cat_val.lower() or "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ" in cat_val:
                    category = "project"
                    category_folder = "11_Projects"

            # å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
            safe_title = "".join(
                c for c in title_preview if c.isalnum() or c in "-_ã‚-ã‚“ã‚¢-ãƒ³ä¸€-é¾¯"
            )[:40]
            filename = f"{timestamp}-{safe_title}.md"
            file_path = f"{category_folder}/{filename}"

            # Use comprehensive YAML frontmatter generator
            yaml_generator = YAMLFrontmatterGenerator()

            # Discord ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®æº–å‚™
            discord_context = {
                "source": "Discord",
                "channel_name": message_data.get("channel_name", "unknown"),
                "message_id": message_data.get("message_id"),
                "user_id": message_data.get("author_id"),
                "timestamp": now_jst,
            }

            # éŸ³å£°ãƒ¡ãƒ¢ã®å ´åˆã®è¿½åŠ æƒ…å ±
            if message_data.get("attachments"):
                for attachment in message_data["attachments"]:
                    if attachment.get("content_type", "").startswith("audio/"):
                        discord_context["is_voice_memo"] = True
                        discord_context["audio_duration"] = attachment.get(
                            "duration", 0
                        )
                        discord_context["input_method"] = "voice"
                        break

            # Generate comprehensive frontmatter
            yaml_frontmatter = yaml_generator.create_comprehensive_frontmatter(
                title=title_preview,
                content_type=category,
                ai_result=ai_result,
                content=content,
                context=discord_context,
                # è¿½åŠ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                vault_section=category_folder,
                processing_timestamp=now_jst,
                auto_generated=True,
                data_quality="high" if ai_result else "medium",
            )

            # Generate comprehensive YAML frontmatter markdown content
            markdown_parts = [
                yaml_frontmatter,
                "",  # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼å¾Œã®ç©ºè¡Œ
                f"# {title_preview}",
                "",
                "## ğŸ“ å†…å®¹",
                "",
                content,
            ]

            # AI åˆ†æçµæœãŒã‚ã‚‹å ´åˆã¯è¿½åŠ æƒ…å ±ã‚’å«ã‚ã‚‹
            if ai_result:
                markdown_parts.extend(["", "---", "", "## AI åˆ†ææƒ…å ±", ""])

                if ai_result.category:
                    confidence = getattr(ai_result.category, "confidence_score", 0)
                    markdown_parts.append(
                        f"- **ã‚«ãƒ†ã‚´ãƒª**: {ai_result.category.category.value} ({confidence:.0%})"
                    )

                if ai_result.summary:
                    markdown_parts.extend(
                        [
                            f"- **è¦ç´„**: {ai_result.summary.summary}",
                        ]
                    )

                if hasattr(ai_result, "tags") and ai_result.tags:
                    # TagsResult ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆã€ tags.tags ã§ã‚¢ã‚¯ã‚»ã‚¹
                    if hasattr(ai_result.tags, "tags"):
                        tags_list: list[str] = ai_result.tags.tags
                    else:
                        # TagResult ã®å ´åˆã¯é©åˆ‡ã«å¤‰æ›
                        if hasattr(ai_result.tags, "__iter__") and not isinstance(
                            ai_result.tags, str
                        ):
                            # TagResult ã® iteration ã‚’å®‰å…¨ã«å‡¦ç†
                            try:
                                tags_list = [str(tag) for tag in ai_result.tags]
                            except (TypeError, AttributeError):
                                tags_list = [str(ai_result.tags)]
                        else:
                            tags_list = [str(ai_result.tags)]

                    # ã‚¿ã‚°ãƒªã‚¹ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆå„è¦ç´ ã‚’æ–‡å­—åˆ—ã¨ã—ã¦å‡¦ç†ï¼‰
                    if isinstance(tags_list, list | tuple):
                        tags_str = ", ".join(str(tag) for tag in tags_list)
                    else:
                        tags_str = str(tags_list)

                    markdown_parts.append(f"- **æ¨å¥¨ã‚¿ã‚°**: {tags_str}")

            # æœ€çµ‚çš„ãªã‚¯ãƒªãƒ¼ãƒ³ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³
            clean_markdown = "\n".join(markdown_parts)

            # GitHub API å¤±æ•—ãƒ•ãƒ©ã‚°
            github_success = False

            # STEP 1: Try GitHub API
            github_token = os.getenv("GITHUB_TOKEN")
            github_repo = "kenvexar/obsidian-vault-test"  # ãƒ†ã‚¹ãƒˆãƒªãƒã‚¸ãƒˆãƒªã«ä¿®æ­£

            if github_token and github_repo:
                try:
                    # GitHub API ã«ç›´æ¥é€ä¿¡
                    headers = {
                        "Authorization": f"token {github_token}",
                        "Accept": "application/vnd.github.v3+json",
                        "User-Agent": "MindBridge-Bot",
                    }

                    url = f"https://api.github.com/repos/{github_repo}/contents/{file_path}"

                    payload = {
                        "message": f"Enhanced YAML: {title_preview}",
                        "content": base64.b64encode(
                            clean_markdown.encode("utf-8")
                        ).decode("utf-8"),
                        "branch": "main",
                    }

                    async with aiohttp.ClientSession() as session:
                        async with session.put(
                            url, headers=headers, json=payload
                        ) as response:
                            if response.status == 201:
                                github_success = True
                            else:
                                pass  # Fall back to local

                except Exception as e:
                    self.logger.debug(
                        "GitHub upload failed, falling back to local", error=str(e)
                    )

            # STEP 2: Local file creation fallback
            local_file_created = False
            if not github_success:
                try:
                    # ãƒ­ãƒ¼ã‚«ãƒ« vault ãƒ‘ã‚¹ã®è¨­å®š
                    vault_path = Path("/app/vault")

                    local_folder = vault_path / category_folder

                    # ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                    local_folder.mkdir(parents=True, exist_ok=True)

                    local_file_path = local_folder / filename

                    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    async with aiofiles.open(
                        local_file_path, "w", encoding="utf-8"
                    ) as f:
                        await f.write(clean_markdown)

                    local_file_created = True

                except Exception as e:
                    self.logger.warning(
                        "Failed to create local note file", error=str(e)
                    )

            # STEP 3: GitHub sync (only if local file was created)
            if local_file_created:
                try:
                    from src.obsidian.github_sync import GitHubObsidianSync

                    # Create GitHub sync instance
                    sync_client = GitHubObsidianSync()

                    # Check configuration
                    if sync_client.is_configured:
                        # Execute auto sync
                        await sync_client.sync_to_github(
                            commit_message=f"Auto-sync Enhanced YAML: {title_preview}"
                        )

                except Exception as e:
                    self.logger.debug(
                        "GitHub sync failed but note is saved locally", error=str(e)
                    )

            return {
                "status": "success",
                "file_path": file_path,
                "github_success": github_success,
                "local_success": local_file_created,
            }

        except Exception as e:
            return {"status": "error", "error": str(e)}

    @staticmethod
    def _generate_title_preview(content: str, audio_data: dict[str, Any] | None) -> str:
        """ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ«ã¨ãªã‚‹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ–‡å­—åˆ—ã‚’ç”Ÿæˆ"""
        if audio_data and audio_data.get("transcript"):
            title_source = audio_data["transcript"].strip()
        else:
            title_source = content.replace("\n", " ").strip()

        title_source = re.sub(r"^[#\s*]+", "", title_source)
        title_source = re.sub(r"[#*]+$", "", title_source)
        title_source = re.sub(r"#{1,6}\s*", "", title_source)
        title_source = re.sub(r"ğŸ¤\s*éŸ³å£°æ–‡å­—èµ·ã“ã—\s*", "", title_source)
        title_source = re.sub(r"éŸ³å£°æ–‡å­—èµ·ã“ã—\s*", "", title_source)
        title_source = re.sub(r"\s{2,}", " ", title_source).strip()

        if not title_source:
            return "éŸ³å£°ãƒ¡ãƒ¢"

        sentence_candidates = re.split(r"[ã€‚ï¼ï¼Ÿ?!]", title_source, maxsplit=1)
        primary_sentence = sentence_candidates[0].strip() if sentence_candidates else ""
        title_preview = primary_sentence or title_source
        return title_preview[:30]

    async def organize_note_by_ai_category(
        self, note_path: str, ai_category: str, ai_result: Any
    ) -> None:
        """AI ã‚«ãƒ†ã‚´ãƒªã«ã‚ˆã‚‹ãƒãƒ¼ãƒˆæ•´ç†"""
        if not ai_result or not ai_result.category:
            self.logger.debug(
                "No AI category found, keeping note in current location",
                note_path=note_path,
            )
            return

        try:
            from src.obsidian.models import FolderMapping

            # AI åˆ†é¡çµæœã‹ã‚‰ç›®æ¨™ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ±ºå®š
            category = ai_result.category.category
            subcategory = getattr(ai_result.category, "subcategory", None)

            target_folder = FolderMapping.get_folder_for_category(category, subcategory)

            # ç¾åœ¨ã®ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’ç¢ºèª
            if self.obsidian_manager is None:
                self.logger.warning("Obsidian manager not available for organization")
                return

            # ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•ã‚’å®Ÿè¡Œ
            # å®Ÿéš›ã®ç§»å‹•å‡¦ç†ã¯ obsidian_manager ã«å§”è­²
            await self.obsidian_manager.organize_note_by_category(
                note_path, target_folder, ai_result
            )

            self.logger.info(
                "Note organized by AI category",
                note_path=note_path,
                target_folder=target_folder.value
                if hasattr(target_folder, "value")
                else str(target_folder),
                category=category,
                subcategory=subcategory,
                confidence=ai_result.category.confidence_score,
            )

        except Exception as e:
            self.logger.error(
                "Failed to organize note by AI category",
                note_path=note_path,
                category=category if "category" in locals() else "unknown",
                error=str(e),
                exc_info=True,
            )

    async def handle_daily_note_integration(
        self, message_data: dict[str, Any], ai_result: Any
    ) -> None:
        """ãƒ‡ã‚¤ãƒªãƒ¼ãƒãƒ¼ãƒˆçµ±åˆå‡¦ç†"""
        try:
            from src.config import get_settings

            settings = get_settings()

            # channel_info ãŒ message_data ã«å«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã®å‡¦ç†
            channel_info = message_data.get("channel_info")
            if not channel_info:
                return

            channel_id = channel_info.id

            # Activity Log ãƒãƒ£ãƒ³ãƒãƒ«ã®å‡¦ç†
            if (
                self.daily_integration
                and hasattr(settings, "channel_activity_log")
                and settings.channel_activity_log
                and channel_id == settings.channel_activity_log
            ):
                success = await self.daily_integration.add_activity_log_entry(
                    message_data
                )
                if success:
                    self.logger.info("Activity log entry added to daily note")
                else:
                    self.logger.warning("Failed to add activity log entry")

            # Daily Tasks ãƒãƒ£ãƒ³ãƒãƒ«ã®å‡¦ç†
            elif (
                self.daily_integration
                and hasattr(settings, "channel_daily_tasks")
                and settings.channel_daily_tasks
                and channel_id == settings.channel_daily_tasks
            ):
                success = await self.daily_integration.add_daily_task_entry(
                    message_data
                )
                if success:
                    self.logger.info("Daily task entry added to daily note")
                else:
                    self.logger.warning("Failed to add daily task entry")

        except Exception as e:
            self.logger.error(
                "Error in daily note integration",
                channel_name=message_data.get("channel_name", "unknown"),
                error=str(e),
                exc_info=True,
            )

    async def handle_github_direct_sync(
        self, note_path: str, channel_info: Any
    ) -> None:
        """GitHub ç›´æ¥åŒæœŸå‡¦ç†"""
        try:
            from src.obsidian.github_direct import GitHubDirectClient

            # GitHub Direct Client ã‚’åˆæœŸåŒ–
            github_client = GitHubDirectClient()

            self.logger.debug(
                "GitHubDirectClient initialized",
                is_configured=github_client.is_configured,
                has_token=bool(github_client.github_token),
                has_repo_url=bool(github_client.github_repo_url),
                owner=github_client.owner,
                repo=github_client.repo,
            )

            if not github_client.is_configured:
                self.logger.warning(
                    "GitHub direct sync not configured - file saved locally only"
                )
                return

            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å†…å®¹ã‚’èª­ã¿å–ã‚Š
            from pathlib import Path

            import aiofiles

            local_path = Path(note_path)
            if not local_path.exists():
                self.logger.warning("Local note file not found", note_path=note_path)
                return

            async with aiofiles.open(local_path, encoding="utf-8") as f:
                content = await f.read()

            # GitHub ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            result = await github_client.create_or_update_file(
                file_path=note_path,
                content=content,
                commit_message=f"Auto-sync: {local_path.stem} from Discord",
            )

            if result:
                self.logger.info(
                    "GitHub direct sync completed successfully",
                    file_path=note_path,
                    commit_sha=result.get("content", {}).get("sha"),
                )
            else:
                self.logger.warning(
                    "GitHub direct sync failed",
                    file_path=note_path,
                    reason="create_or_update_file returned None",
                )

        except ImportError:
            self.logger.warning(
                "GitHubDirectClient not available - falling back to traditional sync"
            )
        except Exception as github_error:
            self.logger.error(
                "GitHub direct sync failed with error",
                file_path=note_path,
                error=str(github_error),
                exc_info=True,
            )

    def generate_ai_based_title(self, text_content: str) -> str:
        """AI åŸºç›¤ã®ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ"""
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸå®Ÿè£… - å®Ÿéš›ã«ã¯ AI çµæœã‚’ä½¿ç”¨
        if len(text_content) > 30:
            return f"ğŸ“ {text_content[:30]}..."
        return f"ğŸ“ {text_content}"

    def generate_text_based_title(self, text_content: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆåŸºç›¤ã®ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ"""
        if text_content and len(text_content) > 10:
            # æœ€åˆã® 30 æ–‡å­—ã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
            clean_text = text_content.strip()[:30]
            return f"ğŸ“ {clean_text}"
        return "ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒ¢"

    def get_fallback_title(self, channel_name: str) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ"""
        return f"ğŸ“ ãƒ¡ãƒ¢ - #{channel_name}"

    def generate_activity_log_title(self, text_content: str) -> str:
        """æ´»å‹•ãƒ­ã‚°ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ"""
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ„å‘³ã®ã‚ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
            if text_content and len(text_content.strip()) > 5:
                # æœ€åˆã®è¡Œã¾ãŸã¯ 30 æ–‡å­—ã‚’ä½¿ç”¨
                first_line = text_content.split("\n")[0].strip()
                if len(first_line) > 30:
                    first_line = first_line[:30] + "..."
                return f"ğŸ“ {first_line}"

            return "ğŸ“ æ´»å‹•ãƒ­ã‚°"

        except Exception:
            return "ğŸ“ æ´»å‹•ãƒ­ã‚°"
