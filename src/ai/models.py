"""
AI å‡¦ç†ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
"""

from datetime import datetime
from enum import Enum
from typing import Any

from pydantic import BaseModel, ConfigDict, Field, field_validator


class ProcessingCategory(Enum):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚«ãƒ†ã‚´ãƒª"""

    WORK = "ä»•äº‹"
    LEARNING = "å­¦ç¿’"
    PROJECT = "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ"
    LIFE = "ç”Ÿæ´»"
    IDEA = "ã‚¢ã‚¤ãƒ‡ã‚¢"
    FINANCE = "é‡‘è"
    TASKS = "ã‚¿ã‚¹ã‚¯"
    HEALTH = "å¥åº·"
    OTHER = "ãã®ä»–"


class ProcessingPriority(Enum):
    """å‡¦ç†å„ªå…ˆåº¦"""

    LOW = "low"
    NORMAL = "normal"
    HIGH = "high"
    URGENT = "urgent"


class AIModelConfig(BaseModel):
    """AI ãƒ¢ãƒ‡ãƒ«è¨­å®š"""

    model_name: str = "models/gemini-2.5-flash"
    temperature: float = Field(default=0.3, ge=0.0, le=2.0)
    max_tokens: int = Field(default=1024, ge=1, le=8192)
    top_p: float = Field(default=0.8, ge=0.0, le=1.0)
    top_k: int = Field(default=40, ge=1, le=100)


class ProcessingSettings(BaseModel):
    """AI å‡¦ç†è¨­å®š"""

    min_text_length: int = Field(default=3, ge=1)  # 3 æ–‡å­—ä»¥ä¸Šã§å‡¦ç†
    max_text_length: int = Field(default=8000, ge=1)
    enable_summary: bool = True
    enable_tags: bool = True
    enable_categorization: bool = True
    max_keywords: int = Field(default=5, ge=1, le=10)
    cache_duration_hours: int = Field(default=24, ge=1)
    retry_count: int = Field(default=3, ge=0, le=10)
    timeout_seconds: int = Field(default=30, ge=5, le=300)

    def __post_init__(self):
        """åˆæœŸåŒ–å¾Œã®è¨­å®šæ¤œè¨¼ã¨å¼·åˆ¶ä¿®æ­£"""
        # ğŸ”§ FORCE FIX: min_text_length ãŒç•°å¸¸ã«å¤§ãã„å ´åˆã¯å¼·åˆ¶çš„ã« 3 ã«è¨­å®š
        if self.min_text_length > 20:
            print(
                f"âš ï¸ WARNING: min_text_length was {self.min_text_length}, forcing to 3"
            )
            object.__setattr__(self, "min_text_length", 3)


class SummaryResult(BaseModel):
    """è¦ç´„çµæœ"""

    summary: str
    key_points: list[str] = Field(default_factory=list)
    confidence_score: float | None = Field(default=None, ge=0.0, le=1.0)
    processing_time_ms: int
    model_used: str


class TagResult(BaseModel):
    """ã‚¿ã‚°æŠ½å‡ºçµæœ"""

    tags: list[str] = Field(default_factory=list)
    raw_keywords: list[str] = Field(default_factory=list)
    confidence_scores: dict[str, float] = Field(default_factory=dict)
    processing_time_ms: int
    model_used: str

    @field_validator("tags")
    @classmethod
    def validate_tags(cls, v: list[str]) -> list[str]:
        """ã‚¿ã‚°ãŒæ­£ã—ã„å½¢å¼ã‹ãƒã‚§ãƒƒã‚¯"""
        validated_tags = []
        for tag in v:
            # #ãŒä»˜ã„ã¦ã„ãªã„å ´åˆã¯è¿½åŠ 
            if not tag.startswith("#"):
                tag = f"#{tag}"
            # ç„¡åŠ¹ãªæ–‡å­—ã‚’é™¤å»
            clean_tag = "".join(
                c for c in tag if c.isalnum() or c in ["#", "_", "-", "ã‚-ã‚“ã‚¢-ãƒ³ä¸€-é¾¯"]
            )
            if len(clean_tag) > 1:  # #ã ã‘ã§ãªã„å ´åˆ
                validated_tags.append(clean_tag)
        return validated_tags[:10]  # æœ€å¤§ 10 å€‹ã¾ã§


class CategoryResult(BaseModel):
    """ã‚«ãƒ†ã‚´ãƒªåˆ†é¡çµæœ"""

    category: ProcessingCategory
    confidence_score: float = Field(ge=0.0, le=1.0)
    alternative_categories: list[dict[str, float]] = Field(default_factory=list)
    reasoning: str | None = None
    processing_time_ms: int
    model_used: str


class AIProcessingResult(BaseModel):
    """AI å‡¦ç†ã®çµ±åˆçµæœ"""

    message_id: int
    processed_at: datetime
    summary: SummaryResult | None = None
    tags: TagResult | None = None
    category: CategoryResult | None = None
    total_processing_time_ms: int
    cache_hit: bool = False
    errors: list[str] = Field(default_factory=list)
    warnings: list[str] = Field(default_factory=list)

    model_config = ConfigDict()


class ProcessingRequest(BaseModel):
    """AI å‡¦ç†ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""

    message_id: int
    text_content: str
    settings: ProcessingSettings
    priority: ProcessingPriority = ProcessingPriority.NORMAL
    force_reprocess: bool = False
    requested_at: datetime = Field(default_factory=datetime.now)

    @field_validator("text_content")
    @classmethod
    def validate_text_content(cls, v: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        if not v or len(v.strip()) == 0:
            raise ValueError("Text content cannot be empty")
        return v.strip()


class ProcessingStats(BaseModel):
    """å‡¦ç†çµ±è¨ˆæƒ…å ±ï¼ˆãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ï¼‰"""

    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    total_processing_time_ms: int = 0
    average_processing_time_ms: float = 0.0
    total_tokens_used: int = 0
    api_calls_made: int = 0
    error_counts: dict[str, int] = Field(default_factory=dict)
    last_updated: datetime = Field(default_factory=datetime.now)

    # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®ãŸã‚ã®åˆ¶é™è¨­å®š
    max_error_entries: int = Field(default=100, exclude=True)  # ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥æ•°ã®ä¸Šé™

    def update_stats(self, result: AIProcessingResult, tokens_used: int = 0) -> None:
        """çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°ï¼ˆãƒ¡ãƒ¢ãƒªåˆ¶é™ä»˜ãï¼‰"""
        self.total_requests += 1

        if result.errors:
            self.failed_requests += 1
            for error in result.errors:
                # ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ã®è“„ç©åˆ¶é™
                if len(self.error_counts) >= self.max_error_entries:
                    # æœ€ã‚‚å¤ã„ã‚¨ãƒ©ãƒ¼ã‚’å‰Šé™¤ï¼ˆç°¡æ˜“çš„ã« LRU ï¼‰
                    oldest_error = min(self.error_counts.items(), key=lambda x: x[1])
                    del self.error_counts[oldest_error[0]]

                self.error_counts[error] = self.error_counts.get(error, 0) + 1
        else:
            self.successful_requests += 1

        if result.cache_hit:
            self.cache_hits += 1
        else:
            self.cache_misses += 1
            self.api_calls_made += 1

        self.total_processing_time_ms += result.total_processing_time_ms
        self.total_tokens_used += tokens_used

        # å¹³å‡å‡¦ç†æ™‚é–“ã‚’æ›´æ–°
        if self.total_requests > 0:
            self.average_processing_time_ms = (
                self.total_processing_time_ms / self.total_requests
            )

        self.last_updated = datetime.now()

    def cleanup_old_errors(self, max_entries: int = 50) -> int:
        """å¤ã„ã‚¨ãƒ©ãƒ¼ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if len(self.error_counts) <= max_entries:
            return 0

        # ç™ºç”Ÿå›æ•°ã®å°‘ãªã„ã‚¨ãƒ©ãƒ¼ã‚’å‰Šé™¤
        sorted_errors = sorted(self.error_counts.items(), key=lambda x: x[1])
        to_remove = len(self.error_counts) - max_entries

        removed_count = 0
        for error, _ in sorted_errors[:to_remove]:
            del self.error_counts[error]
            removed_count += 1

        return removed_count

    def get_memory_usage_estimate(self) -> dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¨å®šå€¤ã‚’å–å¾—"""
        # ç°¡æ˜“çš„ãªãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¨å®š
        error_memory_bytes = sum(
            len(error.encode("utf-8")) for error in self.error_counts.keys()
        )
        base_memory_bytes = 200  # åŸºæœ¬ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¨å®šã‚µã‚¤ã‚º

        return {
            "total_bytes_estimate": error_memory_bytes + base_memory_bytes,
            "error_entries_count": len(self.error_counts),
            "error_memory_bytes": error_memory_bytes,
            "base_memory_bytes": base_memory_bytes,
        }


class ProcessingCache(BaseModel):
    """å‡¦ç†çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥"""

    content_hash: str
    result: AIProcessingResult
    created_at: datetime
    expires_at: datetime
    access_count: int = 0
    last_accessed: datetime = Field(default_factory=datetime.now)

    def is_expired(self) -> bool:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœŸé™åˆ‡ã‚Œã‹ãƒã‚§ãƒƒã‚¯"""
        return datetime.now() > self.expires_at

    def access(self) -> None:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ±ã‚’æ›´æ–°"""
        self.access_count += 1
        self.last_accessed = datetime.now()


class CacheInfo(BaseModel):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆæƒ…å ±"""

    total_entries: int
    memory_usage: float  # MB
    hit_rate: float  # 0.0-1.0


class ProcessingError(BaseModel):
    """å‡¦ç†ã‚¨ãƒ©ãƒ¼æƒ…å ±"""

    error_type: str
    error_message: str
    error_code: str | None = None
    occurred_at: datetime = Field(default_factory=datetime.now)
    retry_count: int = 0
    is_retryable: bool = True
    context: dict[str, Any] = Field(default_factory=dict)


class APIUsageInfo(BaseModel):
    """API ä½¿ç”¨é‡æƒ…å ±"""

    requests_count: int = 0
    tokens_used: int = 0
    cost_estimated: float = 0.0
    rate_limit_remaining: int | None = None
    rate_limit_reset_at: datetime | None = None
    quota_remaining: int | None = None
    last_updated: datetime = Field(default_factory=datetime.now)

    def add_usage(self, tokens: int, estimated_cost: float = 0.0) -> None:
        """ä½¿ç”¨é‡ã‚’è¿½åŠ """
        self.requests_count += 1
        self.tokens_used += tokens
        self.cost_estimated += estimated_cost
        self.last_updated = datetime.now()
