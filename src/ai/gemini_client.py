"""
Google Gemini API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
"""

import asyncio
import time
from typing import Any

try:
    import google.genai  # noqa: F401

    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False

from src.ai.models import (
    AIModelConfig,
    APIUsageInfo,
    CategoryResult,
    ProcessingCategory,
    SummaryResult,
    TagResult,
)
from src.config.settings import get_settings
from src.utils.mixins import LoggerMixin


class GeminiAPIError(Exception):
    """Gemini API é–¢é€£ã®ã‚¨ãƒ©ãƒ¼"""

    def __init__(
        self, message: str, error_code: str | None = None, retryable: bool = False
    ):
        super().__init__(message)
        self.error_code = error_code
        self.retryable = retryable


class RateLimitExceeded(GeminiAPIError):
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼"""

    def __init__(self, retry_after: int | None = None):
        super().__init__("Rate limit exceeded", retryable=True)
        self.retry_after = retry_after


class GeminiClient(LoggerMixin):
    """Google Gemini API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆæ–°ã—ã„ google-genai SDK ä½¿ç”¨ï¼‰"""

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    SUMMARY_PROMPT = """ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã® Discord ã§ã®ä¼šè©±ã‚’ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ç®‡æ¡æ›¸ã 3 ã¤ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
---
{text}
---

è¦ç´„ï¼ˆç®‡æ¡æ›¸ã 3 ç‚¹ï¼‰:"""

    TAG_GENERATION_PROMPT = """ã‚ãªãŸã¯æƒ…å ±ã‚’æ•´ç†ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æœ€ã‚‚é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ 5 ã¤æŠ½å‡ºã—ã€ Obsidian ã§ä½¿ãˆã‚‹ã‚ˆã†ã« '#' ã‚’ã¤ã‘ãŸã‚¿ã‚°å½¢å¼ã§ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ä¾‹: #Python, #AI, #ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°

ãƒ†ã‚­ã‚¹ãƒˆ:
---
{text}
---

ã‚¿ã‚°:"""

    CLASSIFICATION_PROMPT = """ã‚ãªãŸã¯ã‚¿ã‚¹ã‚¯ç®¡ç†ã®ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã‚’åˆ†æã—ã€æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä»¥ä¸‹ã®é¸æŠè‚¢ã‹ã‚‰ä¸€ã¤ã ã‘é¸ã‚“ã§ãã ã•ã„ã€‚

ã‚«ãƒ†ã‚´ãƒª: [ä»•äº‹, å­¦ç¿’, ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ, ç”Ÿæ´», ã‚¢ã‚¤ãƒ‡ã‚¢, é‡‘è, ã‚¿ã‚¹ã‚¯, å¥åº·, ãã®ä»–]

ã‚«ãƒ†ã‚´ãƒªã®å®šç¾©:
- é‡‘è: æ”¯å‡ºãƒ»åå…¥ãƒ»å®¶è³ƒãƒ»æ–™é‡‘ãƒ»æŠ•è³‡ãƒ»è³¼å…¥ãªã©ã€ãŠé‡‘ã«é–¢ã™ã‚‹å†…å®¹
- ã‚¿ã‚¹ã‚¯: TODO ãƒ»ä½œæ¥­ãƒ»ç· åˆ‡ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ãƒ»é€²æ—ãªã©ã€å®Ÿè¡Œã™ã¹ãäº‹é …
- å¥åº·: ä½“é‡ãƒ»é‹å‹•ãƒ»ç¡çœ ãƒ»é£Ÿäº‹ãƒ»åŒ»ç™‚ãƒ»ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ãªã©ã€å¥åº·é–¢é€£ã®è¨˜éŒ²
- å­¦ç¿’: èª­æ›¸ãƒ»å‹‰å¼·ãƒ»æŠ€è¡“å­¦ç¿’ãƒ»çŸ¥è­˜ç¿’å¾—ãƒ»ãƒ¡ãƒ¢ãªã©ã€å­¦ã³ã«é–¢ã™ã‚‹å†…å®¹
- ä»•äº‹: æ¥­å‹™ãƒ»ä¼šè­°ãƒ»å ±å‘Šãƒ»è·å ´é–¢é€£ãªã©ã€ä»•äº‹ã«é–¢ã™ã‚‹å†…å®¹
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ç‰¹å®šã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²è¡Œãƒ»è¨ˆç”»ãƒ»é–‹ç™ºä½œæ¥­ãªã©
- ã‚¢ã‚¤ãƒ‡ã‚¢: æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»ç™ºæƒ³ãƒ»ä¼ç”»ãƒ»ã‚³ãƒ³ã‚»ãƒ—ãƒˆãªã©
- ç”Ÿæ´»: æ—¥å¸¸ã®å‡ºæ¥äº‹ãƒ»é›‘è¨˜ãƒ»ãã®ä»–ã®ç”Ÿæ´»è¨˜éŒ²
- ãã®ä»–: ä¸Šè¨˜ã«å½“ã¦ã¯ã¾ã‚‰ãªã„å†…å®¹

ãƒ†ã‚­ã‚¹ãƒˆ:
---
{text}
---

ã‚«ãƒ†ã‚´ãƒª:"""

    def __init__(self, model_config: AIModelConfig | None = None):
        """
        Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–

        Args:
            model_config: AI ãƒ¢ãƒ‡ãƒ«è¨­å®š
        """
        self.model_config = model_config or AIModelConfig()
        self.api_usage = APIUsageInfo()
        self._client: Any | None = None
        self._last_request_time = 0
        self._min_request_interval = 4.0  # 15 RPM = 4 ç§’é–“éš”

        # API ã‚­ãƒ¼ã®æ¤œè¨¼
        settings = get_settings()
        if not settings.gemini_api_key:
            raise ValueError("GEMINI_API_KEY is not set in environment variables")

        self._initialize_client()

    def _initialize_client(self) -> None:
        """Gemini API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        if not GENAI_AVAILABLE:
            raise ImportError(
                "google-genai is not installed. "
                "Please install it with: pip install google-genai"
            )

        try:
            # API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
            settings = get_settings()
            api_key = settings.gemini_api_key.get_secret_value()

            # ğŸ” DEBUG: API ã‚­ãƒ¼ã®å­˜åœ¨ç¢ºèª
            self.logger.info(
                f"ğŸ” DEBUG: Initializing Gemini with API key length: {len(api_key)}"
            )

            if not api_key or api_key == "your_gemini_api_key_here":
                raise ValueError(
                    "Invalid GEMINI_API_KEY: appears to be placeholder or empty"
                )

            from google import genai

            self._client = genai.Client(api_key=api_key)

            self.logger.info(
                "Gemini client initialized",
                model=self.model_config.model_name,
                temperature=self.model_config.temperature,
            )

        except Exception as e:
            self.logger.error("Failed to initialize Gemini client", error=str(e))
            raise GeminiAPIError(f"Failed to initialize Gemini client: {str(e)}") from e

    async def _rate_limit_check(self) -> None:
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯ã¨å¾…æ©Ÿ"""
        current_time = time.time()
        time_since_last_request = current_time - self._last_request_time

        if time_since_last_request < self._min_request_interval:
            wait_time = self._min_request_interval - time_since_last_request
            self.logger.debug(f"Rate limiting: waiting {wait_time:.2f} seconds")
            await asyncio.sleep(wait_time)

        self._last_request_time = int(time.time())

    async def _call_gemini_api(self, prompt: str, retry_count: int = 3) -> str:
        """
        Gemini API ã‚’å‘¼ã³å‡ºã™å…±é€šé–¢æ•°

        Args:
            prompt: é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            retry_count: ãƒªãƒˆãƒ©ã‚¤å›æ•°

        Returns:
            API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ

        Raises:
            GeminiAPIError: API å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼
        """
        if not self._client:
            raise GeminiAPIError("Gemini client not initialized")

        await self._rate_limit_check()

        for attempt in range(retry_count + 1):
            try:
                self.logger.debug(
                    "Calling Gemini API", attempt=attempt + 1, prompt_length=len(prompt)
                )

                # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’äº‹å‰ã«ãƒã‚§ãƒƒã‚¯
                token_count = await self._count_tokens(prompt)
                if token_count > self.model_config.max_tokens:
                    raise GeminiAPIError(
                        f"Prompt too long: {token_count} tokens (max: {self.model_config.max_tokens})"
                    )

                # API å‘¼ã³å‡ºã—ï¼ˆæ–°ã—ã„ SDK ã®è¨­å®šï¼‰
                from google.genai import types

                generation_config = types.GenerateContentConfig(
                    temperature=self.model_config.temperature,
                    top_p=self.model_config.top_p,
                    top_k=self.model_config.top_k,
                    max_output_tokens=self.model_config.max_tokens,
                )

                response = await self._client.aio.models.generate_content(
                    model=self.model_config.model_name,
                    contents=prompt,
                    config=generation_config,
                )

                if not response.text:
                    raise GeminiAPIError("Empty response from Gemini API")

                # ä½¿ç”¨é‡ã‚’æ›´æ–°
                self.api_usage.add_usage(token_count)

                self.logger.debug(
                    "Gemini API call successful",
                    response_length=len(response.text),
                    tokens_used=token_count,
                )

                return response.text.strip() if response.text else ""

            except Exception as e:
                error_msg = str(e)

                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®æ¤œå‡º
                if "429" in error_msg or "rate limit" in error_msg.lower():
                    if attempt < retry_count:
                        wait_time = (2**attempt) * 2  # ã‚¨ã‚¯ã‚¹ãƒãƒãƒ³ã‚·ãƒ£ãƒ«ãƒãƒƒã‚¯ã‚ªãƒ•
                        self.logger.warning(
                            "Rate limit hit, retrying",
                            attempt=attempt + 1,
                            wait_time=wait_time,
                        )
                        await asyncio.sleep(wait_time)
                        continue
                    raise RateLimitExceeded() from e

                # ãã®ä»–ã® API ã‚¨ãƒ©ãƒ¼
                self.logger.error(
                    "Gemini API call failed", attempt=attempt + 1, error=error_msg
                )

                if attempt == retry_count:
                    raise GeminiAPIError(
                        f"API call failed after {retry_count + 1} attempts: {error_msg}"
                    ) from e

                # ãƒªãƒˆãƒ©ã‚¤å‰ã®å¾…æ©Ÿ
                await asyncio.sleep(1 * (attempt + 1))

        raise GeminiAPIError("Unexpected error in API call")

    async def _count_tokens(self, text: str) -> int:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ

        Args:
            text: ã‚«ã‚¦ãƒ³ãƒˆå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        try:
            if self._client:
                response = await self._client.aio.models.count_tokens(
                    model=self.model_config.model_name,
                    contents=text,
                )
                return int(response.total_tokens)
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ¦‚ç®—è¨ˆç®—
            return len(text.encode("utf-8")) // 4
        except Exception as e:
            self.logger.warning("Failed to count tokens, using fallback", error=str(e))
            return len(text.encode("utf-8")) // 4

    async def generate_summary(self, text: str) -> SummaryResult:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®è¦ç´„ã‚’ç”Ÿæˆ

        Args:
            text: è¦ç´„å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            è¦ç´„çµæœ
        """
        start_time = time.time()

        try:
            prompt = self.SUMMARY_PROMPT.format(text=text)
            response_text = await self._call_gemini_api(prompt)

            # ç®‡æ¡æ›¸ããƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
            key_points = []
            for line in response_text.split("\n"):
                line = line.strip()
                if line and (
                    line.startswith("ãƒ»")
                    or line.startswith("-")
                    or line.startswith("*")
                ):
                    # è¨˜å·ã‚’é™¤å»ã—ã¦ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
                    point = line.lstrip("ãƒ»-*").strip()
                    if point:
                        key_points.append(point)

            processing_time = int((time.time() - start_time) * 1000)

            return SummaryResult(
                summary=response_text,
                key_points=key_points,
                processing_time_ms=processing_time,
                model_used=self.model_config.model_name,
            )

        except Exception as e:
            processing_time = int((time.time() - start_time) * 1000)
            self.logger.error("Failed to generate summary", error=str(e))

            return SummaryResult(
                summary=f"è¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                key_points=[],
                processing_time_ms=processing_time,
                model_used=self.model_config.model_name,
            )

    async def extract_tags(self, text: str) -> TagResult:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚¿ã‚°ã‚’æŠ½å‡º

        Args:
            text: ã‚¿ã‚°æŠ½å‡ºå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            ã‚¿ã‚°æŠ½å‡ºçµæœ
        """
        start_time = time.time()

        try:
            prompt = self.TAG_GENERATION_PROMPT.format(text=text)
            response_text = await self._call_gemini_api(prompt)

            # ã‚¿ã‚°ã‚’æŠ½å‡ºã—ã¦æ­£è¦åŒ–
            raw_tags = [tag.strip() for tag in response_text.split(",")]
            tags = []
            raw_keywords = []

            for tag in raw_tags:
                if tag:
                    # #ã‚’é™¤å»ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
                    keyword = tag.lstrip("#").strip()
                    if keyword:
                        raw_keywords.append(keyword)
                        # æ­£è¦åŒ–ã•ã‚ŒãŸã‚¿ã‚°ã‚’è¿½åŠ 
                        formatted_tag = f"#{keyword}"
                        tags.append(formatted_tag)

            processing_time = int((time.time() - start_time) * 1000)

            return TagResult(
                tags=tags[:5],  # æœ€å¤§ 5 å€‹ã¾ã§
                raw_keywords=raw_keywords[:5],
                processing_time_ms=processing_time,
                model_used=self.model_config.model_name,
            )

        except Exception as e:
            processing_time = int((time.time() - start_time) * 1000)
            self.logger.error("Failed to extract tags", error=str(e))

            return TagResult(
                tags=[],
                raw_keywords=[],
                processing_time_ms=processing_time,
                model_used=self.model_config.model_name,
            )

    async def classify_category(self, text: str) -> CategoryResult:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®ã‚«ãƒ†ã‚´ãƒªã‚’åˆ†é¡

        Args:
            text: åˆ†é¡å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            ã‚«ãƒ†ã‚´ãƒªåˆ†é¡çµæœ
        """
        start_time = time.time()

        try:
            prompt = self.CLASSIFICATION_PROMPT.format(text=text)
            response_text = await self._call_gemini_api(prompt)

            # ã‚«ãƒ†ã‚´ãƒªåã‚’æ­£è¦åŒ–
            category_text = response_text.lower().strip()

            # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°
            category_mapping = {
                "ä»•äº‹": ProcessingCategory.WORK,
                "work": ProcessingCategory.WORK,
                "å­¦ç¿’": ProcessingCategory.LEARNING,
                "learning": ProcessingCategory.LEARNING,
                "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ": ProcessingCategory.PROJECT,
                "project": ProcessingCategory.PROJECT,
                "ç”Ÿæ´»": ProcessingCategory.LIFE,
                "life": ProcessingCategory.LIFE,
                "ã‚¢ã‚¤ãƒ‡ã‚¢": ProcessingCategory.IDEA,
                "idea": ProcessingCategory.IDEA,
                "é‡‘è": ProcessingCategory.FINANCE,
                "finance": ProcessingCategory.FINANCE,
                "ã‚¿ã‚¹ã‚¯": ProcessingCategory.TASKS,
                "tasks": ProcessingCategory.TASKS,
                "task": ProcessingCategory.TASKS,
                "å¥åº·": ProcessingCategory.HEALTH,
                "health": ProcessingCategory.HEALTH,
                "ãã®ä»–": ProcessingCategory.OTHER,
                "other": ProcessingCategory.OTHER,
            }

            # ãƒãƒƒãƒã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’æ¢ç´¢
            detected_category = ProcessingCategory.OTHER
            confidence = 0.5

            for key, cat in category_mapping.items():
                if key in category_text:
                    detected_category = cat
                    confidence = 0.8
                    break

            processing_time = int((time.time() - start_time) * 1000)

            return CategoryResult(
                category=detected_category,
                confidence_score=confidence,
                reasoning=f"åˆ†é¡æ ¹æ‹ : {response_text}",
                processing_time_ms=processing_time,
                model_used=self.model_config.model_name,
            )

        except Exception as e:
            processing_time = int((time.time() - start_time) * 1000)
            self.logger.error("Failed to classify category", error=str(e))

            return CategoryResult(
                category=ProcessingCategory.OTHER,
                confidence_score=0.0,
                reasoning=f"åˆ†é¡ã‚¨ãƒ©ãƒ¼: {str(e)}",
                processing_time_ms=processing_time,
                model_used=self.model_config.model_name,
            )

    async def process_all(
        self, text: str
    ) -> tuple[SummaryResult, TagResult, CategoryResult]:
        """
        ã™ã¹ã¦ã® AI å‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œ

        Args:
            text: å‡¦ç†å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            è¦ç´„ã€ã‚¿ã‚°ã€ã‚«ãƒ†ã‚´ãƒªã®çµæœã‚¿ãƒ—ãƒ«
        """
        self.logger.info("Starting parallel AI processing", text_length=len(text))

        # ä¸¦åˆ—å®Ÿè¡Œ
        summary_task = self.generate_summary(text)
        tags_task = self.extract_tags(text)
        category_task = self.classify_category(text)

        try:
            summary, tags, category = await asyncio.gather(
                summary_task, tags_task, category_task, return_exceptions=True
            )

            # ä¾‹å¤–å‡¦ç†
            if isinstance(summary, Exception):
                self.logger.error("Summary generation failed", error=str(summary))
                summary = SummaryResult(
                    summary="è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ",
                    processing_time_ms=0,
                    model_used=self.model_config.model_name,
                )

            if isinstance(tags, Exception):
                self.logger.error("Tag extraction failed", error=str(tags))
                tags = TagResult(
                    tags=[],
                    raw_keywords=[],
                    processing_time_ms=0,
                    model_used=self.model_config.model_name,
                )

            if isinstance(category, Exception):
                self.logger.error("Category classification failed", error=str(category))
                category = CategoryResult(
                    category=ProcessingCategory.OTHER,
                    confidence_score=0.0,
                    processing_time_ms=0,
                    model_used=self.model_config.model_name,
                )

            # å‹ãƒã‚§ãƒƒã‚¯ï¼ˆä¾‹å¤–ã§ã¯ãªã„å ´åˆã®ã¿å‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²ï¼‰
            summary_time = (
                summary.processing_time_ms if isinstance(summary, SummaryResult) else 0
            )
            tags_time = tags.processing_time_ms if isinstance(tags, TagResult) else 0
            category_time = (
                category.processing_time_ms
                if isinstance(category, CategoryResult)
                else 0
            )

            self.logger.info(
                "Parallel AI processing completed",
                summary_time=summary_time,
                tags_time=tags_time,
                category_time=category_time,
            )

            # ä¾‹å¤–ãŒãªã„å ´åˆã®ã¿æ­£å¸¸ãªçµæœã‚’è¿”ã™
            if (
                isinstance(summary, SummaryResult)
                and isinstance(tags, TagResult)
                and isinstance(category, CategoryResult)
            ):
                return summary, tags, category
            # ä¾‹å¤–ãŒã‚ã£ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿ
            raise GeminiAPIError("One or more parallel processing tasks failed")

        except Exception as e:
            self.logger.error("Parallel processing failed", error=str(e))
            raise GeminiAPIError(f"Parallel processing failed: {str(e)}") from e

    def get_usage_info(self) -> APIUsageInfo:
        """API ä½¿ç”¨é‡æƒ…å ±ã‚’å–å¾—"""
        return self.api_usage

    def reset_usage_info(self) -> None:
        """API ä½¿ç”¨é‡æƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.api_usage = APIUsageInfo()
        self.logger.info("API usage info reset")
