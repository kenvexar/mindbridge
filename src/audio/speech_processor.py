"""
Speech processing and transcription using Google Cloud Speech-to-Text API
"""

import os
from datetime import datetime
from pathlib import Path
from typing import Any

import aiofiles
import aiohttp
from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential,
)

from src.audio.models import (
    AudioFormat,
    AudioProcessingResult,
    SpeechAPIUsage,
    TranscriptionResult,
)
from src.config import get_settings
from src.utils.mixins import LoggerMixin


class RetryableAPIError(Exception):
    """ãƒªãƒˆãƒ©ã‚¤å¯èƒ½ãª API ã‚¨ãƒ©ãƒ¼"""


class NonRetryableAPIError(Exception):
    """ãƒªãƒˆãƒ©ã‚¤ä¸å¯èƒ½ãª API ã‚¨ãƒ©ãƒ¼"""


class SpeechProcessor(LoggerMixin):
    """éŸ³å£°å‡¦ç†ã¨çµ±åˆæ–‡å­—èµ·ã“ã—ã‚·ã‚¹ãƒ†ãƒ ï¼ˆè¤‡æ•°ã‚¨ãƒ³ã‚¸ãƒ³å¯¾å¿œï¼‰"""

    def __init__(self) -> None:
        """åˆæœŸåŒ–å‡¦ç†"""
        self.usage_tracker = SpeechAPIUsage()
        self.supported_formats = {
            "mp3": AudioFormat.MP3,
            "wav": AudioFormat.WAV,
            "flac": AudioFormat.FLAC,
            "ogg": AudioFormat.OGG,
            "m4a": AudioFormat.M4A,
            "webm": AudioFormat.WEBM,
        }

        # æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ã®å„ªå…ˆé †ä½ã¨åˆ©ç”¨å¯èƒ½æ€§ç¢ºèª
        self.transcription_engines: list[dict[str, Any]] = []
        self._setup_transcription_engines()

        # API åˆ©ç”¨å¯èƒ½æ€§ãƒ•ãƒ©ã‚°
        self.api_available = (
            len(
                [
                    e
                    for e in self.transcription_engines
                    if e["name"] != "file_save_fallback"
                ]
            )
            > 0
        )

        self.logger.info(
            "éŸ³å£°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†",
            available_engines=[engine["name"] for engine in self.transcription_engines],
            primary_engine=(
                self.transcription_engines[0]["name"]
                if self.transcription_engines
                else "none"
            ),
        )

    def _setup_transcription_engines(self) -> None:
        """æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨åˆ©ç”¨å¯èƒ½æ€§ç¢ºèª"""
        self.transcription_engines = []

        # Google Cloud Speech-to-Text API
        if self._check_google_speech_api_availability():
            self.transcription_engines.append(
                {
                    "name": "google_cloud_speech",
                    "method": self._transcribe_audio,  # å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
                    "priority": 1,
                }
            )

        # ãƒ­ãƒ¼ã‚«ãƒ« Whisper ãƒ¢ãƒ‡ãƒ«ï¼ˆç°¡æ˜“ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        # æ³¨æ„: _transcribe_with_local_whisper ãƒ¡ã‚½ãƒƒãƒ‰ã¯æœªå®Ÿè£…ã®ãŸã‚ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        # if self._check_local_whisper_availability():
        #     self.transcription_engines.append({
        #         'name': 'local_whisper',
        #         'method': self._transcribe_with_local_whisper,
        #         'priority': 2
        #     })

        # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã®ã¿
        self.transcription_engines.append(
            {"name": "file_save_fallback", "method": None, "priority": 999}  # ç‰¹åˆ¥å‡¦ç†
        )

        if not self.transcription_engines:
            self.logger.warning("æ–‡å­—èµ·ã“ã—ã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

    def _check_google_speech_api_availability(self) -> bool:
        """ã‚°ãƒ¼ã‚°ãƒ« Speech API ã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ç¢ºèª"""
        try:
            settings = get_settings()
            # API ã‚­ãƒ¼ã¾ãŸã¯èªè¨¼æƒ…å ±ã®ç¢ºèª
            if (
                hasattr(settings, "google_cloud_speech_api_key")
                and settings.google_cloud_speech_api_key
            ):
                return True

            if (
                hasattr(settings, "google_application_credentials")
                and settings.google_application_credentials
            ):
                credentials_path = Path(settings.google_application_credentials)
                if credentials_path.exists():
                    return True

            # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®ç¢ºèª
            if os.environ.get("GOOGLE_APPLICATION_CREDENTIALS"):
                return True

            if os.environ.get("GOOGLE_CLOUD_SPEECH_API_KEY"):
                return True

            self.logger.debug("Google Cloud Speech API credentials not found")
            return False

        except Exception as e:
            self.logger.error(
                "Error checking Google Speech API availability", error=str(e)
            )
            return False

    def _check_local_whisper_availability(self) -> bool:
        """ãƒ­ãƒ¼ã‚«ãƒ« Whisper ã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ç¢ºèª"""
        try:
            # whisper ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª
            import importlib.util

            if importlib.util.find_spec("whisper") is not None:
                self.logger.info("Local Whisper model available")
                return True
            return False
        except ImportError:
            self.logger.debug(
                "Local Whisper not available (whisper package not installed)"
            )
            return False
        except Exception as e:
            self.logger.debug("Error checking local Whisper availability", error=str(e))
            return False

    async def process_audio_file(
        self, file_data: bytes, filename: str, channel_name: str | None = None
    ) -> AudioProcessingResult:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ

        Args:
            file_data: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            channel_name: Discord ãƒãƒ£ãƒ³ãƒãƒ«å

        Returns:
            éŸ³å£°å‡¦ç†çµæœ
        """
        start_time = datetime.now()

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®æ¤œè¨¼
            audio_format = self._detect_audio_format(filename)
            if not audio_format:
                return self._create_error_result(
                    filename=filename,
                    file_size=len(file_data),
                    error="Unsupported audio format",
                    processing_time_ms=0,
                )

            # éŸ³å£°å“è³ªã®äº‹å‰æ¤œè¨¼
            quality_check = await self._validate_audio_quality(file_data, audio_format)
            if not quality_check["valid"]:
                return self._create_error_result(
                    filename=filename,
                    file_size=len(file_data),
                    error=quality_check["error"],
                    processing_time_ms=int(
                        (datetime.now() - start_time).total_seconds() * 1000
                    ),
                )

            self.logger.info(
                "Processing audio file",
                filename=filename,
                size_bytes=len(file_data),
                format=audio_format.value,
            )

            # API åˆ¶é™ã®ç¢ºèª
            if self.usage_tracker.is_limit_exceeded:
                return await self._handle_fallback(
                    file_data=file_data,
                    filename=filename,
                    audio_format=audio_format,
                    reason="API limit exceeded",
                    start_time=start_time,
                )

            # éŸ³å£°ã®é•·ã•ã‚’æ¨å®šï¼ˆæ¦‚ç®—ï¼‰
            estimated_duration = self._estimate_audio_duration(file_data, audio_format)

            # API åˆ©ç”¨å¯èƒ½æ€§ã®ç¢ºèª
            if not self.api_available:
                return await self._handle_fallback(
                    file_data=file_data,
                    filename=filename,
                    audio_format=audio_format,
                    reason="API not available",
                    start_time=start_time,
                )

            # Google Cloud Speech-to-Text API ã§æ–‡å­—èµ·ã“ã—
            transcription_result = await self._transcribe_audio(file_data, audio_format)

            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)

            # ä½¿ç”¨é‡ã‚’è¿½è·¡
            if estimated_duration:
                duration_minutes = estimated_duration / 60.0
                self.usage_tracker.add_usage(duration_minutes, success=True)

            return AudioProcessingResult(
                success=True,
                transcription=transcription_result,
                original_filename=filename,
                file_size_bytes=len(file_data),
                audio_format=audio_format,
                duration_seconds=estimated_duration,
                processing_time_ms=processing_time,
                api_usage_minutes=duration_minutes if estimated_duration else 0.0,
            )

        except Exception as e:
            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)

            self.logger.error(
                "Audio processing failed",
                filename=filename,
                error=str(e),
                exc_info=True,
            )

            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return await self._handle_fallback(
                file_data=file_data,
                filename=filename,
                audio_format=audio_format or AudioFormat.MP3,
                reason=f"Processing error: {str(e)}",
                start_time=start_time,
            )

    def _detect_audio_format(self, filename: str) -> AudioFormat | None:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ¤œå‡º"""
        try:
            extension = Path(filename).suffix.lower().lstrip(".")
            detected_format = self.supported_formats.get(extension)

            return detected_format
        except Exception as e:
            self.logger.warning(
                "Failed to detect audio format", filename=filename, error=str(e)
            )
            return None

    def _estimate_audio_duration(
        self, file_data: bytes, audio_format: AudioFormat
    ) -> float | None:
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        try:
            # ç°¡æ˜“çš„ãªæ¨å®šï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯éŸ³å£°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ï¼‰
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒ™ãƒ¼ã‚¹ã®æ¦‚ç®—
            size_mb = len(file_data) / (1024 * 1024)

            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åŸºã¥ãæ¦‚ç®—ï¼ˆéå¸¸ã«å¤§ã¾ã‹ãªæ¨å®šï¼‰
            if audio_format in [AudioFormat.MP3, AudioFormat.M4A]:
                # åœ§ç¸®å½¢å¼: 1MB ã‚ãŸã‚Šç´„ 1 åˆ†ç¨‹åº¦
                estimated_duration = size_mb * 60
            elif audio_format in [AudioFormat.WAV, AudioFormat.FLAC]:
                # éåœ§ç¸®å½¢å¼: ã‚ˆã‚ŠçŸ­ã„
                estimated_duration = size_mb * 10
            else:
                # ãã®ä»–
                estimated_duration = size_mb * 30

            # ç¾å®Ÿçš„ãªç¯„å›²ã«åˆ¶é™
            return max(1.0, min(estimated_duration, 600.0))  # 1 ç§’ã€œ 10 åˆ†

        except Exception as e:
            self.logger.warning("Failed to estimate audio duration", error=str(e))
            return None

    async def _transcribe_audio(
        self, file_data: bytes, audio_format: AudioFormat
    ) -> TranscriptionResult:
        """Google Cloud Speech-to-Text API ã§éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—"""
        try:
            # Google Cloud Speech API ã‚’ä½¿ç”¨ï¼ˆå®Ÿéš›ã®å®Ÿè£…ï¼‰
            settings = get_settings()
            if (
                hasattr(settings, "google_cloud_speech_api_key")
                and settings.google_cloud_speech_api_key
            ):
                return await self._transcribe_with_rest_api(file_data, audio_format)
            return await self._transcribe_with_client_library(file_data, audio_format)

        except (RetryableAPIError, NonRetryableAPIError) as e:
            self.logger.error("API transcription failed after retries", error=str(e))
            # API ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å«ã‚ã‚‹
            error_msg = self._get_user_friendly_error_message(str(e))
            return TranscriptionResult.create_from_confidence(
                transcript=f"[{error_msg}]",
                confidence=0.0,
                processing_time_ms=0,
                model_used="error",
            )
        except Exception as e:
            self.logger.error(
                "Unexpected transcription error", error=str(e), exc_info=True
            )
            # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
            return TranscriptionResult.create_from_confidence(
                transcript="[éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ]",
                confidence=0.0,
                processing_time_ms=0,
                model_used="error",
            )

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type(RetryableAPIError),
    )
    async def _transcribe_with_rest_api(
        self, file_data: bytes, audio_format: AudioFormat
    ) -> TranscriptionResult:
        """REST API ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
        import base64

        start_time = datetime.now()

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            encoded_audio = base64.b64encode(file_data).decode("utf-8")

            # API ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒšã‚¤ãƒ­ãƒ¼ãƒ‰
            request_data = {
                "config": {
                    "encoding": self._get_encoding_for_format(audio_format),
                    "sampleRateHertz": 16000,
                    "languageCode": "ja-JP",
                    "enableWordTimeOffsets": True,
                    "enableAutomaticPunctuation": True,
                    "model": "latest_short",
                },
                "audio": {"content": encoded_audio},
            }

            # API ã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            settings = get_settings()
            if settings.google_cloud_speech_api_key is None:
                raise ValueError("Google Cloud Speech API key is not configured")
            api_key = settings.google_cloud_speech_api_key.get_secret_value()
            url = f"https://speech.googleapis.com/v1/speech:recognize?key={api_key}"

            async with (
                aiohttp.ClientSession(
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as session,
                session.post(url, json=request_data) as response,
            ):
                # HTTP ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ãåˆ†å²å‡¦ç†
                if response.status == 200:
                    result = await response.json()
                elif response.status == 429:  # Rate limit
                    self.logger.warning("API rate limit exceeded")
                    raise NonRetryableAPIError("API rate limit exceeded")
                elif response.status >= 500:  # Server errors
                    error_text = await response.text()
                    self.logger.warning(
                        "API server error - will retry",
                        status=response.status,
                        error=error_text,
                    )
                    raise RetryableAPIError(
                        f"Server error: {response.status} - {error_text}"
                    )
                elif response.status == 400:  # Bad request
                    error_text = await response.text()
                    self.logger.error(
                        "API bad request - will not retry",
                        status=response.status,
                        error=error_text,
                    )
                    raise NonRetryableAPIError(
                        f"Bad request: {response.status} - {error_text}"
                    )
                else:
                    error_text = await response.text()
                    self.logger.warning(
                        "API client error - will retry once",
                        status=response.status,
                        error=error_text,
                    )
                    raise RetryableAPIError(
                        f"Client error: {response.status} - {error_text}"
                    )

            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            if "results" in result and result["results"]:
                alternative = result["results"][0]["alternatives"][0]
                transcript = alternative.get("transcript", "")
                confidence = alternative.get("confidence", 0.0)

                self.logger.info(
                    "Speech API transcription successful",
                    transcript_length=len(transcript),
                    confidence=confidence,
                    processing_time_ms=processing_time,
                )

                return TranscriptionResult.create_from_confidence(
                    transcript=transcript,
                    confidence=confidence,
                    processing_time_ms=processing_time,
                    model_used="google-speech-latest_short",
                    words=alternative.get("words", []),
                    alternatives=result["results"][0].get("alternatives", []),
                )
            # çµæœãªã—
            self.logger.info("No speech detected in audio")
            return TranscriptionResult.create_from_confidence(
                transcript="[éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ]",
                confidence=0.0,
                processing_time_ms=processing_time,
                model_used="google-speech-latest_short",
            )

        except (RetryableAPIError, NonRetryableAPIError):
            # ã“ã‚Œã‚‰ã¯æ—¢ã«é©åˆ‡ã«ãƒ­ã‚°å‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€å†ç™ºç”Ÿã•ã›ã‚‹
            raise
        except Exception as e:
            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)
            self.logger.error(
                "Unexpected error in REST API transcription",
                error=str(e),
                exc_info=True,
            )

            return TranscriptionResult.create_from_confidence(
                transcript=f"[äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}]",
                confidence=0.0,
                processing_time_ms=processing_time,
                model_used="google-speech-error",
            )

    def _get_audio_properties(
        self, file_data: bytes, audio_format: AudioFormat
    ) -> tuple[int, int]:
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã¨ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’å–å¾—"""
        try:
            from io import BytesIO

            from pydub import AudioSegment

            audio_segment = AudioSegment.from_file(
                BytesIO(file_data), format=audio_format.value
            )
            return audio_segment.frame_rate, audio_segment.channels
        except Exception as e:
            self.logger.warning(f"Failed to get audio properties: {e}, using defaults")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤: 16kHz ãƒ¢ãƒãƒ©ãƒ« (Google Cloud Speech API ã®æœ€å°è¦ä»¶)
            return 16000, 1

    async def _transcribe_with_client_library(
        self, file_data: bytes, audio_format: AudioFormat
    ) -> TranscriptionResult:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—"""
        start_time = datetime.now()

        try:
            # ğŸ”§ FIX: å®Ÿéš›ã® Google Cloud Speech ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨
            import io

            from google.cloud import speech

            self.logger.info(
                "Using Google Cloud Speech client library for transcription",
                audio_size=len(file_data),
                format=audio_format.value,
            )

            # ğŸ”§ IMPROVEMENT: OGG Opus ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ 16-bit WAV ã«å¤‰æ›ã—ã¦ã‹ã‚‰å‡¦ç†
            processed_audio_data = file_data
            target_format = audio_format

            if audio_format == AudioFormat.OGG:
                self.logger.info("Converting OGG Opus to WAV for better compatibility")
                try:
                    import io

                    from pydub import AudioSegment

                    # OGG ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                    audio_segment = AudioSegment.from_file(
                        io.BytesIO(file_data), format="ogg"
                    )

                    # ğŸ”§ FIX: 16-bit, 48kHz ãƒ¢ãƒãƒ©ãƒ«ã«æ­£è¦åŒ–ï¼ˆ Google Cloud Speech API å¯¾å¿œï¼‰
                    audio_segment = (
                        audio_segment.set_frame_rate(48000)
                        .set_channels(1)
                        .set_sample_width(2)
                    )  # 2 bytes = 16 bit

                    # WAV ã¨ã—ã¦å‡ºåŠ›
                    wav_buffer = io.BytesIO()
                    audio_segment.export(wav_buffer, format="wav")
                    processed_audio_data = wav_buffer.getvalue()
                    target_format = AudioFormat.WAV

                    self.logger.info(
                        "Successfully converted OGG to WAV",
                        original_size=len(file_data),
                        converted_size=len(processed_audio_data),
                        sample_rate=audio_segment.frame_rate,
                        channels=audio_segment.channels,
                        sample_width_bits=audio_segment.sample_width * 8,
                    )

                except Exception as convert_error:
                    self.logger.warning(
                        "Failed to convert OGG to WAV, using original",
                        error=str(convert_error),
                    )

            # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
            client = speech.SpeechClient()

            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            audio = speech.RecognitionAudio(content=processed_audio_data)

            # ğŸ”§ NEW: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿéš›ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’å–å¾—
            sample_rate, channels = self._get_audio_properties(
                processed_audio_data, target_format
            )

            self.logger.info(
                "Detected audio properties",
                sample_rate=sample_rate,
                channels=channels,
                format=target_format.value,
            )

            # ğŸ”§ IMPROVED: ã‚ˆã‚ŠæŸ”è»Ÿãªèªè­˜è¨­å®š
            encoding = self._get_speech_encoding_for_format(target_format)

            self.logger.info(
                "Audio format mapping",
                input_format=target_format.value,
                speech_encoding=encoding.name if encoding else "None",
            )

            config = speech.RecognitionConfig(
                encoding=encoding,
                sample_rate_hertz=sample_rate,  # ğŸ”§ FIX: å®Ÿéš›ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨
                audio_channel_count=channels,  # ğŸ”§ FIX: å®Ÿéš›ã®ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’ä½¿ç”¨
                language_code="ja-JP",
                alternative_language_codes=["en-US"],  # è‹±èªã‚‚å¯¾å¿œ
                enable_automatic_punctuation=True,
                enable_word_time_offsets=True,
                enable_word_confidence=True,
                model="latest_long",  # ã‚ˆã‚Šæ±ç”¨çš„ãªãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´
                use_enhanced=True,  # é«˜å“è³ªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            )

            # éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œ
            self.logger.info("Starting Google Cloud Speech recognition")
            response = client.recognize(config=config, audio=audio)

            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)

            # çµæœã‚’å‡¦ç†
            if response.results:
                # ã™ã¹ã¦ã®çµæœã‚’ç¢ºèª
                all_alternatives = []
                best_transcript = ""
                best_confidence = 0.0

                for result in response.results:
                    for alternative in result.alternatives:
                        all_alternatives.append(
                            {
                                "transcript": alternative.transcript,
                                "confidence": alternative.confidence,
                            }
                        )

                        if alternative.confidence > best_confidence:
                            best_transcript = alternative.transcript
                            best_confidence = alternative.confidence

                self.logger.info(
                    "Google Cloud Speech transcription successful",
                    transcript_length=len(best_transcript),
                    confidence=best_confidence,
                    alternatives_count=len(all_alternatives),
                    processing_time_ms=processing_time,
                )

                return TranscriptionResult.create_from_confidence(
                    transcript=best_transcript,
                    confidence=best_confidence,
                    processing_time_ms=processing_time,
                    model_used="google-speech-client-library",
                )
            else:
                # éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆã®è©³ç´°æƒ…å ±
                self.logger.warning(
                    "No speech detected in audio",
                    audio_size=len(processed_audio_data),
                    format=target_format.value,
                    processing_time_ms=processing_time,
                )
                return TranscriptionResult.create_from_confidence(
                    transcript="[éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚éŸ³é‡ã‚’ä¸Šã’ã‚‹ã‹ã€ã‚ˆã‚Šã¯ã£ãã‚Šã¨è©±ã—ã¦ãã ã•ã„ã€‚]",
                    confidence=0.0,
                    processing_time_ms=processing_time,
                    model_used="google-speech-client-library",
                )

        except ImportError as import_error:
            # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆ
            missing_lib = (
                "pydub" if "pydub" in str(import_error) else "google-cloud-speech"
            )
            self.logger.warning(
                f"{missing_lib} library not installed, using fallback transcription"
            )
            return await self._fallback_mock_transcription(
                file_data, audio_format, start_time
            )

        except Exception as e:
            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)
            self.logger.error(
                "Google Cloud Speech transcription failed", error=str(e), exc_info=True
            )

            # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±
            error_message = str(e)
            if "quota" in error_message.lower() or "limit" in error_message.lower():
                transcript = (
                    "[API åˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ãŠè©¦ã—ãã ã•ã„ã€‚]"
                )
            elif (
                "invalid" in error_message.lower()
                or "format" in error_message.lower()
                or "sample rate" in error_message.lower()
                or "bit" in error_message.lower()
            ):
                transcript = "[éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ MP3 ã‚„ WAV ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚]"
            else:
                transcript = f"[éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {error_message[:100]}{'...' if len(error_message) > 100 else ''}]"

            return TranscriptionResult.create_from_confidence(
                transcript=transcript,
                confidence=0.0,
                processing_time_ms=processing_time,
                model_used="google-speech-error",
            )

    async def _fallback_mock_transcription(
        self, file_data: bytes, audio_format: AudioFormat, start_time: datetime
    ) -> TranscriptionResult:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ¢ãƒƒã‚¯æ–‡å­—èµ·ã“ã—"""
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºã«åŸºã¥ã„ã¦ç•°ãªã‚‹è»¢å†™çµæœã‚’ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
        audio_size = len(file_data)
        processing_delay = min(2.0, max(1.0, audio_size / 10000))  # ã‚µã‚¤ã‚ºã«åŸºã¥ãé…å»¶

        await self._simulate_processing_delay(processing_delay)

        # ğŸ”§ FIX: ã‚µã‚¤ã‚ºã«åŸºã¥ã„ã¦ç•°ãªã‚‹è»¢å†™çµæœã‚’ç”Ÿæˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
        if audio_size < 5000:
            transcript = "ã“ã‚“ã«ã¡ã¯ã€ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚"
        elif audio_size < 10000:
            transcript = "éŸ³å£°ãƒ¡ãƒ¢ã®ãƒ†ã‚¹ãƒˆã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚æ­£å¸¸ã«æ–‡å­—èµ·ã“ã—ã•ã‚Œã¾ã—ãŸã€‚"
        else:
            transcript = "é•·ã‚ã®éŸ³å£°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚ Discord ã‹ã‚‰ Obsidian ã¸ã®é€£æºãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚"

        processing_time = int((datetime.now() - start_time).total_seconds() * 1000)

        return TranscriptionResult.create_from_confidence(
            transcript=transcript,
            confidence=0.85,
            processing_time_ms=processing_time,
            model_used="mock-fallback",
        )

    def _get_speech_encoding_for_format(self, audio_format: AudioFormat):
        """Google Cloud Speech ç”¨ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å½¢å¼ã‚’å–å¾—"""
        from google.cloud import speech

        format_mapping = {
            AudioFormat.MP3: speech.RecognitionConfig.AudioEncoding.MP3,
            AudioFormat.WAV: speech.RecognitionConfig.AudioEncoding.LINEAR16,
            AudioFormat.FLAC: speech.RecognitionConfig.AudioEncoding.FLAC,
            AudioFormat.OGG: speech.RecognitionConfig.AudioEncoding.OGG_OPUS,
            AudioFormat.M4A: speech.RecognitionConfig.AudioEncoding.MP3,  # M4A ã¯é€šå¸¸ AAC ã ãŒã€ MP3 ã¨ã—ã¦å‡¦ç†
            AudioFormat.WEBM: speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
        }

        encoding = format_mapping.get(
            audio_format, speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED
        )

        self.logger.info(
            "Audio format mapping",
            input_format=audio_format.value,
            speech_encoding=encoding.name
            if hasattr(encoding, "name")
            else str(encoding),
        )

        return encoding

    async def _simulate_processing_delay(self, delay_seconds: float = 1.0) -> None:
        """å‡¦ç†ã®é…å»¶ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
        import asyncio

        await asyncio.sleep(delay_seconds)  # 1 ç§’ã®é…å»¶ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ

    def _get_encoding_for_format(self, audio_format: AudioFormat) -> str:
        """éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åã‚’å–å¾—"""
        format_mapping = {
            AudioFormat.MP3: "MP3",
            AudioFormat.WAV: "LINEAR16",
            AudioFormat.FLAC: "FLAC",
            AudioFormat.OGG: "OGG_OPUS",
            AudioFormat.M4A: "MP3",  # M4A ã¯é€šå¸¸ AAC ã ãŒã€ MP3 ã¨ã—ã¦å‡¦ç†
            AudioFormat.WEBM: "WEBM_OPUS",
        }
        return format_mapping.get(audio_format, "LINEAR16")

    async def _handle_fallback(
        self,
        file_data: bytes,
        filename: str,
        audio_format: AudioFormat,
        reason: str,
        start_time: datetime,
    ) -> AudioProcessingResult:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¦æ‰‹å‹•å‡¦ç†ç”¨ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
        try:
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            saved_path = await self._save_audio_file_for_manual_processing(
                file_data, filename
            )

            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯çµæœã‚’ä½œæˆ
            fallback_transcript = (
                f"[éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {saved_path}]\n"
                f"åˆ¶é™ç†ç”±: {reason}\n"
                f"æ‰‹å‹•ã§æ–‡å­—èµ·ã“ã—ã‚’è¡Œã†ã‹ã€ API åˆ¶é™ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã¾ã§ãŠå¾…ã¡ãã ã•ã„ã€‚"
            )

            transcription = TranscriptionResult.create_from_confidence(
                transcript=fallback_transcript,
                confidence=0.0,
                processing_time_ms=processing_time,
                model_used="fallback-file-save",
            )

            return AudioProcessingResult(
                success=False,
                transcription=transcription,
                original_filename=filename,
                file_size_bytes=len(file_data),
                audio_format=audio_format,
                processing_time_ms=processing_time,
                fallback_used=True,
                fallback_reason=reason,
                saved_file_path=saved_path,
            )

        except Exception as e:
            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)

            return self._create_error_result(
                filename=filename,
                file_size=len(file_data),
                error=f"Fallback failed: {str(e)}",
                processing_time_ms=processing_time,
            )

    async def _save_audio_file_for_manual_processing(
        self, file_data: bytes, filename: str
    ) -> str:
        """æ‰‹å‹•å‡¦ç†ç”¨ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜"""
        try:
            from src.obsidian.models import VaultFolder

            # Obsidian vault å†…ã® audio ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜
            settings = get_settings()

            audio_dir = (
                Path(settings.obsidian_vault_path)
                / VaultFolder.ATTACHMENTS.value
                / "Audio"
            )
            audio_dir.mkdir(parents=True, exist_ok=True)

            # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_filename = Path(filename).stem[:50]  # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’åˆ¶é™
            extension = Path(filename).suffix or ".mp3"

            saved_filename = f"{timestamp}_{safe_filename}{extension}"
            saved_path = audio_dir / saved_filename

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            async with aiofiles.open(saved_path, "wb") as f:
                await f.write(file_data)

            self.logger.info(
                "Audio file saved for manual processing",
                filename=filename,
                saved_path=str(saved_path),
            )

            return str(saved_path)

        except Exception as e:
            self.logger.error("Failed to save audio file", error=str(e), exc_info=True)
            raise

    def _create_error_result(
        self, filename: str, file_size: int, error: str, processing_time_ms: int
    ) -> AudioProcessingResult:
        """ã‚¨ãƒ©ãƒ¼çµæœã‚’ä½œæˆ"""
        return AudioProcessingResult(
            success=False,
            transcription=None,
            error_message=error,
            original_filename=filename,
            file_size_bytes=file_size,
            audio_format=AudioFormat.MP3,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            processing_time_ms=processing_time_ms,
        )

    def get_usage_stats(self) -> dict[str, Any]:
        """API ä½¿ç”¨é‡çµ±è¨ˆã‚’å–å¾—"""
        return {
            "monthly_usage_minutes": self.usage_tracker.monthly_usage_minutes,
            "monthly_limit_minutes": self.usage_tracker.monthly_limit_minutes,
            "usage_percentage": self.usage_tracker.usage_percentage,
            "remaining_minutes": self.usage_tracker.remaining_minutes,
            "is_limit_exceeded": self.usage_tracker.is_limit_exceeded,
            "total_requests": self.usage_tracker.total_requests,
            "successful_requests": self.usage_tracker.successful_requests,
            "failed_requests": self.usage_tracker.failed_requests,
            "last_updated": self.usage_tracker.last_updated.isoformat(),
        }

    def reset_monthly_usage(self) -> None:
        """æœˆé–“ä½¿ç”¨é‡ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.usage_tracker.reset_monthly_usage()
        self.logger.info("Monthly usage reset")

    def _get_user_friendly_error_message(self, error_msg: str) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¤‰æ›"""
        if "API rate limit exceeded" in error_msg or "429" in error_msg:
            return "ä»Šæœˆã® API åˆ©ç”¨ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚æ¥æœˆã¾ã§ãŠå¾…ã¡ã„ãŸã ãã‹ã€æ‰‹å‹•ã§ã®æ–‡å­—èµ·ã“ã—ã‚’ãŠé¡˜ã„ã—ã¾ã™"
        if "Server error" in error_msg or "5" in error_msg[:1]:
            return "API ã‚µãƒ¼ãƒãƒ¼ã§ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„"
        if "Bad request" in error_msg or "400" in error_msg:
            return "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹å½¢å¼ï¼ˆ MP3 ã€ WAV ã€ FLAC ç­‰ï¼‰ã‚’ã”åˆ©ç”¨ãã ã•ã„"
        if "timeout" in error_msg.lower():
            return "å‡¦ç†æ™‚é–“ãŒé•·ã™ãã‚‹ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚çŸ­ã„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã§ãŠè©¦ã—ãã ã•ã„"
        return "ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„"

    async def _validate_audio_quality(
        self, file_data: bytes, audio_format: AudioFormat
    ) -> dict[str, Any]:
        """éŸ³å£°å“è³ªã®äº‹å‰æ¤œè¨¼"""
        try:
            from io import BytesIO

            from pydub import AudioSegment

            # éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
            audio_segment = AudioSegment.from_file(
                BytesIO(file_data), format=audio_format.value
            )

            # é•·ã•ã®æ¤œè¨¼
            duration_ms = len(audio_segment)
            if duration_ms < 500:  # 0.5 ç§’æœªæº€
                return {
                    "valid": False,
                    "error": "éŸ³å£°ãŒçŸ­ã™ãã¾ã™ï¼ˆ 0.5 ç§’æœªæº€ï¼‰ã€‚æ–‡å­—èµ·ã“ã—ã«ã¯æœ€ä½ 0.5 ç§’ä»¥ä¸Šã®éŸ³å£°ãŒå¿…è¦ã§ã™ã€‚",
                    "duration_ms": duration_ms,
                }

            if duration_ms > 60 * 60 * 1000:  # 1 æ™‚é–“ä»¥ä¸Š
                return {
                    "valid": False,
                    "error": "éŸ³å£°ãŒé•·ã™ãã¾ã™ï¼ˆ 1 æ™‚é–“ä»¥ä¸Šï¼‰ã€‚ API åˆ¶é™ã®ãŸã‚ã€ 60 åˆ†ä»¥å†…ã®éŸ³å£°ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚",
                    "duration_ms": duration_ms,
                }

            # éŸ³é‡ãƒ¬ãƒ™ãƒ«ã®æ¤œè¨¼ï¼ˆç„¡éŸ³ãƒã‚§ãƒƒã‚¯ï¼‰
            try:
                dBFS = audio_segment.dBFS
                if dBFS < -60:  # ã»ã¼ç„¡éŸ³
                    return {
                        "valid": False,
                        "error": "éŸ³å£°ãƒ¬ãƒ™ãƒ«ãŒéå¸¸ã«ä½ã„ã€ã¾ãŸã¯ç„¡éŸ³çŠ¶æ…‹ã§ã™ã€‚ãƒã‚¤ã‚¯ã®è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
                        "duration_ms": duration_ms,
                        "dBFS": dBFS,
                    }

                # éå¸¸ã«ä½ã„éŸ³é‡ã®è­¦å‘Š
                if dBFS < -40:
                    self.logger.warning(
                        "Low audio volume detected", dBFS=dBFS, duration_ms=duration_ms
                    )

            except Exception as e:
                # éŸ³é‡ãƒã‚§ãƒƒã‚¯ãŒå¤±æ•—ã—ã¦ã‚‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œ
                self.logger.debug("Audio volume check failed", error=str(e))

            # ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã®ç¢ºèª
            channels = audio_segment.channels
            if channels > 2:
                self.logger.info(
                    "Multi-channel audio detected, will be processed as-is",
                    channels=channels,
                )

            # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã®ç¢ºèª
            frame_rate = audio_segment.frame_rate
            if frame_rate < 8000:
                return {
                    "valid": False,
                    "error": f"ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆï¼ˆ{frame_rate}Hz ï¼‰ãŒä½ã™ãã¾ã™ã€‚ 8kHz ä»¥ä¸Šã®éŸ³å£°ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚",
                    "duration_ms": duration_ms,
                    "frame_rate": frame_rate,
                }

            self.logger.info(
                "Audio quality validation passed",
                duration_ms=duration_ms,
                dBFS=getattr(audio_segment, "dBFS", "unknown"),
                channels=channels,
                frame_rate=frame_rate,
            )

            return {
                "valid": True,
                "duration_ms": duration_ms,
                "channels": channels,
                "frame_rate": frame_rate,
                "dBFS": getattr(audio_segment, "dBFS", None),
            }

        except ImportError:
            self.logger.warning(
                "pydub not available, skipping audio quality validation"
            )
            return {"valid": True}  # pydub ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

        except Exception as e:
            self.logger.error(
                "Audio quality validation failed", error=str(e), exc_info=True
            )
            # æ¤œè¨¼ã«å¤±æ•—ã—ãŸå ´åˆã¯å‡¦ç†ã‚’ç¶™ç¶š
            return {"valid": True, "warning": f"éŸ³å£°å“è³ªæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"}

    def is_audio_file(self, filename: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãŒéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        result = self._detect_audio_format(filename) is not None
        return result
