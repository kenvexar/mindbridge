# é–‹ç™ºã‚¬ã‚¤ãƒ‰

ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‹ã‚‰å®Ÿè£…ã¾ã§ã€ MindBridge é–‹ç™ºã®åŒ…æ‹¬çš„ã‚¬ã‚¤ãƒ‰ã€‚

## ğŸ” ã‚¯ã‚¤ãƒƒã‚¯ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

```bash
# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
uv sync --dev

# å®Ÿè¡Œ
uv run python -m src.main

# ãƒ†ã‚¹ãƒˆ / ã‚«ãƒãƒ¬ãƒƒã‚¸
uv run pytest -q
uv run pytest --cov=src --cov-report=term-missing

# å“è³ª
uv run ruff check . --fix && uv run ruff format .
uv run mypy src

# ãƒ•ãƒƒã‚¯
uv run pre-commit run --all-files
```

## ç›®æ¬¡

1. [é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)
2. [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ](#ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ )
3. [é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼](#é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼)
4. [ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³](#ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³)
5. [ãƒ†ã‚¹ãƒˆæˆ¦ç•¥](#ãƒ†ã‚¹ãƒˆæˆ¦ç•¥)
6. [ãƒ‡ãƒãƒƒã‚°æŠ€è¡“](#ãƒ‡ãƒãƒƒã‚°æŠ€è¡“)
7. [æ–°æ©Ÿèƒ½é–‹ç™º](#æ–°æ©Ÿèƒ½é–‹ç™º)
8. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–)

## ğŸš€ é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### å¿…è¦ãƒ„ãƒ¼ãƒ«

```bash
# å¿…é ˆãƒ„ãƒ¼ãƒ«
python --version          # 3.13+
uv --version              # æœ€æ–°ç‰ˆ
git --version             # 2.20+
docker --version          # 20.10+ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

# æ¨å¥¨ãƒ„ãƒ¼ãƒ«
code --version            # VS Code
curl --version            # HTTP ãƒ†ã‚¹ãƒˆ
jq --version              # JSON å‡¦ç†
```

### ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
git clone https://github.com/kenvexar/mindbridge.git
cd mindbridge
uv sync --dev
cp .env.example .env.development
```

### VS Code è¨­å®š

`.vscode/settings.json`:
```json
{
    "python.pythonPath": "./.venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.ruffEnabled": true,
    "python.formatting.provider": "ruff",
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests/"],
    "python.testing.autoTestDiscoverOnSaveEnabled": true,
    "files.exclude": {
        "**/__pycache__": true,
        "**/*.pyc": true,
        ".mypy_cache": true,
        ".pytest_cache": true,
        ".ruff_cache": true
    },
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
        "source.organizeImports": "explicit",
        "source.fixAll.ruff": "explicit"
    }
}
```

`.vscode/extensions.json`:
```json
{
    "recommendations": [
        "ms-python.python",
        "charliermarsh.ruff",
        "ms-python.mypy-type-checker",
        "ms-vscode.vscode-json",
        "redhat.vscode-yaml",
        "ms-python.debugpy"
    ]
}
```

### é–‹ç™ºè¨­å®š

`.env.development`:
```env
# é–‹ç™ºç’°å¢ƒ
ENVIRONMENT=development
LOG_LEVEL=DEBUG
LOG_FORMAT=pretty

# Mock ãƒ¢ãƒ¼ãƒ‰ï¼ˆ API ã‚­ãƒ¼ãªã—ã§ãƒ†ã‚¹ãƒˆï¼‰
ENABLE_MOCK_MODE=true
MOCK_DISCORD_ENABLED=true
MOCK_GEMINI_ENABLED=true
MOCK_GARMIN_ENABLED=true
MOCK_SPEECH_ENABLED=true

# ãƒ†ã‚¹ãƒˆç”¨ Obsidian ãƒœãƒ«ãƒˆ
OBSIDIAN_VAULT_PATH=./test_vault

# Discord è¨­å®šï¼ˆå®Ÿéš›ã®ãƒœãƒƒãƒˆã§ãƒ†ã‚¹ãƒˆã™ã‚‹å ´åˆï¼‰
# DISCORD_BOT_TOKEN=your_dev_token
# DISCORD_GUILD_ID=your_test_server_id
# GEMINI_API_KEY=your_dev_key

# é–‹ç™ºæ©Ÿèƒ½
ENABLE_AUTO_RELOAD=true
ENABLE_DEBUG_ENDPOINTS=true
ENABLE_PROFILING=false
```

## ğŸ—ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```
src/
â”œâ”€â”€ config/              # è¨­å®šç®¡ç†
â”‚   â”œâ”€â”€ settings.py         # Pydantic ã‚’ä½¿ã£ãŸãƒ¡ã‚¤ãƒ³è¨­å®š
â”‚   â””â”€â”€ secure_settings.py  # æš—å·åŒ–ä»˜ãã‚»ã‚­ãƒ¥ã‚¢è¨­å®š
â”œâ”€â”€ utils/               # å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨ãƒ­ã‚°
â”‚   â”œâ”€â”€ logger.py           # æ§‹é€ åŒ–ãƒ­ã‚°ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
â”‚   â””â”€â”€ mixins.py           # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒŸãƒƒã‚¯ã‚¹ã‚¤ãƒ³
â”œâ”€â”€ security/            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨èªè¨¼
â”‚   â”œâ”€â”€ secret_manager.py   # ç§˜å¯†æƒ…å ±ç®¡ç†
â”‚   â””â”€â”€ access_logger.py    # ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°
â”œâ”€â”€ bot/                 # Discord ãƒœãƒƒãƒˆå®Ÿè£…
â”‚   â”œâ”€â”€ client.py           # ãƒ¡ã‚¤ãƒ³ Discord ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ handlers.py         # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
â”‚   â”œâ”€â”€ commands/           # ã‚³ãƒãƒ³ãƒ‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ mixins/             # å†åˆ©ç”¨å¯èƒ½ãªãƒœãƒƒãƒˆãƒŸãƒƒã‚¯ã‚¹ã‚¤ãƒ³
â”‚   â””â”€â”€ models.py           # ãƒœãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ ai/                  # AI å‡¦ç†ã¨åˆ†æ
â”‚   â”œâ”€â”€ processor.py        # ãƒ¡ã‚¤ãƒ³ AI ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼
â”‚   â”œâ”€â”€ gemini_client.py    # Google Gemini API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ note_analyzer.py    # ãƒãƒ¼ãƒˆåˆ†æã¨åˆ†é¡
â”‚   â””â”€â”€ models.py           # AI ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ obsidian/            # Obsidian ãƒœãƒ«ãƒˆçµ±åˆ
â”‚   â”œâ”€â”€ core/               # ã‚³ã‚¢ãƒœãƒ«ãƒˆæ“ä½œ
â”‚   â”œâ”€â”€ search/             # æ¤œç´¢æ©Ÿèƒ½
â”‚   â”œâ”€â”€ backup/             # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†
â”‚   â”œâ”€â”€ analytics/          # ãƒœãƒ«ãƒˆåˆ†æ
â”‚   â”œâ”€â”€ models.py           # Obsidian ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”‚   â””â”€â”€ template_system.py  # é«˜åº¦ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”œâ”€â”€ tasks/               # ã‚¿ã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â””â”€â”€ models.py           # ã‚¿ã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ finance/             # è²¡å‹™ç®¡ç†
â”‚   â””â”€â”€ models.py           # è²¡å‹™ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ audio/               # éŸ³å£°å‡¦ç†
â”‚   â””â”€â”€ models.py           # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ garmin/              # Garmin Connect çµ±åˆ
â”‚   â””â”€â”€ models.py           # Garmin ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ health_analysis/     # å¥åº·ãƒ‡ãƒ¼ã‚¿å‡¦ç†
â”‚   â””â”€â”€ models.py           # å¥åº·ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ monitoring/          # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç›£è¦–
â”‚   â””â”€â”€ health_server.py    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚µãƒ¼ãƒãƒ¼
â””â”€â”€ main.py              # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
```

### ä¸»è¦ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³

1. **ä¾å­˜æ€§æ³¨å…¥**: ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¾å­˜æ€§ç®¡ç†
2. **Factory ãƒ‘ã‚¿ãƒ¼ãƒ³**: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆã¨è¨­å®š
3. **Strategy ãƒ‘ã‚¿ãƒ¼ãƒ³**: ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å¼å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰
4. **Template Method ãƒ‘ã‚¿ãƒ¼ãƒ³**: å…±é€šå‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
5. **Repository ãƒ‘ã‚¿ãƒ¼ãƒ³**: ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã®æŠ½è±¡åŒ–
6. **Observer ãƒ‘ã‚¿ãƒ¼ãƒ³**: ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•é€šçŸ¥

### ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¾å­˜é–¢ä¿‚

```mermaid
graph TD
    A[main.py] --> B[bot/client.py]
    B --> C[bot/handlers.py]
    C --> D[ai/processor.py]
    D --> E[obsidian/core/vault_manager.py]
    B --> F[bot/commands/]
    F --> G[tasks/task_manager.py]
    F --> H[finance/expense_manager.py]
    D --> I[ai/gemini_client.py]
    E --> J[obsidian/template_system.py]
```

## ğŸ”„ é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### æ—¥å¸¸çš„ãªé–‹ç™º

```bash
# 1. é–‹ç™ºç”¨ã«èµ·å‹•ï¼ˆå¿…è¦ãªã‚‰ --debugï¼‰
uv run python -m src.main --dev

# 2. ãƒ†ã‚¹ãƒˆ
uv run pytest -q

# 3. å“è³ªãƒã‚§ãƒƒã‚¯
uv run ruff check . --fix && uv run ruff format .
uv run mypy src/
```

### æ©Ÿèƒ½é–‹ç™ºã‚µã‚¤ã‚¯ãƒ«

1. **è¨ˆç”»ãƒ•ã‚§ãƒ¼ã‚º**
   ```bash
   # æ©Ÿèƒ½ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ
   git checkout -b feature/new-ai-classification

   # è¦ä»¶ã‚’æ–‡æ›¸åŒ–
   echo "## æ©Ÿèƒ½: æ‹¡å¼µ AI åˆ†é¡" > docs/features/ai-classification.md
   ```

2. **å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º**
   ```bash
   # æœ€åˆã«ãƒ†ã‚¹ãƒˆã‚’ä½œæˆ (TDD)
   touch tests/unit/test_new_classification.py

   # æ©Ÿèƒ½ã‚’å®Ÿè£…
   # src/ai/enhanced_classifier.py ã‚’ç·¨é›†

   # å®Ÿè£…ã‚’æ¤œè¨¼
   uv run pytest tests/unit/test_new_classification.py -v
   ```

3. **çµ±åˆãƒ•ã‚§ãƒ¼ã‚º**
   ```bash
   # çµ±åˆãƒ†ã‚¹ãƒˆ
   uv run pytest tests/integration/ -v

   # æ‰‹å‹•ãƒ†ã‚¹ãƒˆ
   uv run python -m src.main --dev
   ```

4. **å“è³ªä¿è¨¼**
   ```bash
   # å®Œå…¨ãªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
   uv run pytest --cov=src

   # ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯
   uv run ruff check src/ --fix && uv run ruff format src/
   uv run mypy src/

   # Pre-commit æ¤œè¨¼
   uv run pre-commit run --all-files
   ```

### Git ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```bash
# Daily workflow
git checkout main
git pull origin main
git checkout -b feature/new-feature

# Development commits
git add src/new_module.py tests/test_new_module.py
git commit -m "feat: implement new AI classification module"

# Before push
uv run pytest
uv run ruff check src/ --fix && uv run ruff format src/
git push origin feature/new-feature

# Create PR when ready
gh pr create --title "Add enhanced AI classification" --body "Implementation details..."
```

## ğŸ“ Code Style and Guidelines

### Ruff è¨­å®š

`pyproject.toml`:
```toml
[tool.ruff]
target-version = "py313"
line-length = 88
select = [
    "E",    # pycodestyle errors
    "W",    # pycodestyle warnings
    "F",    # pyflakes
    "I",    # isort
    "B",    # flake8-bugbear
    "C4",   # flake8-comprehensions
    "UP",   # pyupgrade
    "SIM",  # flake8-simplify
]
ignore = [
    "E501",  # line too long, handled by formatter
    "B008",  # do not perform function calls in argument defaults
    "C901",  # too complex
]

[tool.ruff.per-file-ignores]
"tests/**/*" = ["D", "S101", "PLR2004"]

[tool.ruff.mccabe]
max-complexity = 10

[tool.ruff.isort]
known-first-party = ["src"]
```

### ã‚³ãƒ¼ãƒ‰è¦ç´„

**1. Type Hints**
```python
# Good
async def process_message(
    content: str,
    metadata: dict[str, Any]
) -> ProcessingResult:
    """Process message with AI analysis."""
    pass

# Bad
async def process_message(content, metadata):
    pass
```

**2. Error Handling**
```python
# Good
try:
    result = await ai_processor.analyze(content)
except APIError as e:
    logger.error("AI processing failed", extra={"error": str(e), "content_length": len(content)})
    raise ProcessingError(f"Analysis failed: {e}") from e
except Exception as e:
    logger.exception("Unexpected error in AI processing")
    raise

# Bad
try:
    result = await ai_processor.analyze(content)
except:
    print("Error occurred")
    return None
```

**3. Logging**
```python
# Good
logger.info(
    "Message processed successfully",
    extra={
        "message_id": message.id,
        "channel": message.channel.name,
        "processing_time": processing_time,
        "ai_confidence": result.confidence
    }
)

# Bad
print(f"Processed message {message.id}")
```

**4. Async/Await**
```python
# Good
async def save_to_obsidian(note: Note) -> Path:
    """Save note to Obsidian vault."""
    async with aiofiles.open(note.path, "w") as f:
        await f.write(note.content)
    return note.path

# Bad
def save_to_obsidian(note: Note) -> Path:
    with open(note.path, "w") as f:
        f.write(note.content)
    return note.path
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### ãƒ†ã‚¹ãƒˆæ§‹é€ 

```
tests/
â”œâ”€â”€ unit/                # Unit tests
â”‚   â”œâ”€â”€ test_ai/
â”‚   â”œâ”€â”€ test_bot/
â”‚   â”œâ”€â”€ test_obsidian/
â”‚   â””â”€â”€ test_config/
â”œâ”€â”€ integration/         # Integration tests
â”‚   â”œâ”€â”€ test_ai_obsidian.py
â”‚   â”œâ”€â”€ test_discord_flow.py
â”‚   â””â”€â”€ test_end_to_end.py
â”œâ”€â”€ fixtures/            # Test fixtures
â”‚   â”œâ”€â”€ discord_messages.json
â”‚   â”œâ”€â”€ ai_responses.json
â”‚   â””â”€â”€ obsidian_notes.md
â””â”€â”€ conftest.py          # Pytest configuration
```

### ãƒ†ã‚¹ãƒˆä½œæˆ

**Unit Test Example:**
```python
# tests/unit/test_ai/test_processor.py
import pytest
from unittest.mock import AsyncMock, MagicMock

from src.ai.processor import AIProcessor
from src.ai.models import ProcessingResult

@pytest.fixture
def ai_processor():
    """Create AI processor with mocked dependencies."""
    gemini_client = AsyncMock()
    return AIProcessor(gemini_client=gemini_client)

@pytest.mark.asyncio
async def test_process_message_success(ai_processor):
    """Test successful message processing."""
    # Arrange
    content = "Test message about Python programming"
    expected_result = ProcessingResult(
        summary="Programming discussion",
        tags=["python", "programming"],
        category="knowledge",
        confidence=0.85
    )
    ai_processor.gemini_client.analyze.return_value = expected_result

    # Act
    result = await ai_processor.process_message(content)

    # Assert
    assert result.summary == "Programming discussion"
    assert "python" in result.tags
    assert result.category == "knowledge"
    ai_processor.gemini_client.analyze.assert_called_once_with(content)
```

**Integration Test Example:**
```python
# tests/integration/test_discord_to_obsidian.py
import pytest
import tempfile
from pathlib import Path

from src.bot.client import DiscordBot
from src.obsidian.core.vault_manager import VaultManager

@pytest.mark.asyncio
async def test_full_message_processing_flow():
    """Test complete flow from Discord message to Obsidian note."""
    with tempfile.TemporaryDirectory() as temp_dir:
        # Arrange
        vault_path = Path(temp_dir) / "test_vault"
        vault_manager = VaultManager(vault_path)

        # Create mock Discord message
        mock_message = create_mock_discord_message(
            content="Today I learned about async/await in Python",
            author="test_user",
            channel_name="memo"
        )

        # Act
        bot = DiscordBot(vault_manager=vault_manager)
        await bot.process_message(mock_message)

        # Assert
        created_files = list(vault_path.rglob("*.md"))
        assert len(created_files) == 1

        note_content = created_files[0].read_text()
        assert "async/await" in note_content
        assert "Python" in note_content
        assert "tags: [\"python\", \"programming\", \"learning\"]" in note_content
```

### ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=src --cov-report=html

# Run specific test file
uv run pytest tests/unit/test_ai/test_processor.py -v

# Run tests matching pattern
uv run pytest -k "test_message_processing" -v

# Run tests with live logging
uv run pytest --log-cli-level=INFO

# Run in parallel
uv run pytest -n auto
```

### ãƒ†ã‚¹ãƒˆè¨­å®š

`pytest.ini`:
```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
asyncio_mode = auto
markers =
    unit: Unit tests
    integration: Integration tests
    slow: Slow tests
    external: Tests requiring external services
addopts =
    --strict-markers
    --tb=short
    --capture=no
    -ra
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
```

## ğŸ› ãƒ‡ãƒãƒƒã‚°æŠ€è¡“

### ãƒ‡ãƒãƒƒã‚°è¨­å®š

```python
# src/utils/debug.py
import logging
import sys
from typing import Any

def setup_debug_logging() -> None:
    """Setup debug logging configuration."""
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime) s - %(name) s - %(levelname) s - %(message) s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('debug.log')
        ]
    )

def debug_print(obj: Any, name: str = "DEBUG") -> None:
    """Enhanced debug printing."""
    print(f"\n=== {name} ===")
    print(f"Type: {type(obj)}")
    print(f"Value: {obj}")
    if hasattr(obj, '__dict__'):
        print(f"Attributes: {obj.__dict__}")
    print("=" * (len(name) + 8))
```

### Discord Bot ã®ãƒ‡ãƒãƒƒã‚°

```python
# Debug Discord events
@bot.event
async def on_message(message: discord.Message) -> None:
    """Debug message processing."""
    logger.debug(
        "Received message",
        extra={
            "message_id": message.id,
            "content": message.content[:100],
            "author": str(message.author),
            "channel": message.channel.name,
            "guild": message.guild.name if message.guild else None
        }
    )

    # Process message with error handling
    try:
        await process_message_handler(message)
    except Exception as e:
        logger.exception(
            "Message processing failed",
            extra={
                "message_id": message.id,
                "error": str(e)
            }
        )
```

### AI å‡¦ç†ã®ãƒ‡ãƒãƒƒã‚°

```python
# Debug AI processing
async def debug_ai_analysis(content: str) -> ProcessingResult:
    """Debug AI analysis with detailed logging."""
    logger.debug("Starting AI analysis", extra={"content_length": len(content)})

    start_time = time.time()
    try:
        result = await gemini_client.analyze(content)
        processing_time = time.time() - start_time

        logger.debug(
            "AI analysis completed",
            extra={
                "processing_time": processing_time,
                "confidence": result.confidence,
                "tags_count": len(result.tags),
                "category": result.category
            }
        )
        return result
    except Exception as e:
        logger.exception("AI analysis failed", extra={"content": content[:200]})
        raise
```

### Docker ãƒ‡ãƒãƒƒã‚°

```bash
# Debug in Docker container
./scripts/docker-local-test.sh

# Access container for debugging
docker compose exec mindbridge-bot /bin/bash

# View container logs
docker compose logs -f mindbridge-bot

# Debug with volume mounts for live code changes
docker compose -f docker-compose.debug.yml up
```

## ğŸš€ New Feature Development

### æ©Ÿèƒ½é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹

1. **Requirements Analysis**
   ```markdown
   # Feature: Enhanced AI Classification

   ## Problem
   Current AI classification has limited accuracy for technical content.

   ## Solution
   Implement specialized classifiers for different content types.

   ## Acceptance Criteria
   - [ ] 95%+ accuracy for programming content
   - [ ] Support for 10+ programming languages
   - [ ] Performance under 2 seconds
   ```

2. **Design Phase**
   ```python
   # Design interfaces first
   from abc import ABC, abstractmethod

   class ContentClassifier(ABC):
       @abstractmethod
       async def classify(self, content: str) -> ClassificationResult:
           pass

   class ProgrammingClassifier(ContentClassifier):
       async def classify(self, content: str) -> ClassificationResult:
           # Implementation here
           pass
   ```

3. **Test-Driven Development**
   ```python
   # Write tests first
   @pytest.mark.asyncio
   async def test_programming_classifier_python_code():
       """Test classification of Python code snippets."""
       classifier = ProgrammingClassifier()
       content = "def fibonacci(n): return n if n <= 1 else fibonacci(n-1) + fibonacci(n-2)"

       result = await classifier.classify(content)

       assert result.category == "programming"
       assert "python" in result.tags
       assert result.confidence > 0.9
   ```

### æ–°ã—ã„ã‚³ãƒãƒ³ãƒ‰ã®è¿½åŠ 

```python
# src/bot/commands/new_commands.py
from discord import app_commands
from discord.ext import commands

class NewCommands(commands.Cog):
    """New feature commands."""

    def __init__(self, bot: commands.Bot):
        self.bot = bot

    @app_commands.command(name="new_feature")
    @app_commands.describe(
        parameter="Description of parameter"
    )
    async def new_feature_command(
        self,
        interaction: discord.Interaction,
        parameter: str
    ) -> None:
        """Implement new feature."""
        await interaction.response.defer()

        try:
            result = await self.process_new_feature(parameter)
            await interaction.followup.send(f"âœ… Feature result: {result}")
        except Exception as e:
            logger.exception("New feature command failed")
            await interaction.followup.send(f"âŒ Error: {e}")

    async def process_new_feature(self, parameter: str) -> str:
        """Process new feature logic."""
        # Implementation here
        return f"Processed: {parameter}"

async def setup(bot: commands.Bot) -> None:
    """Setup function for the cog."""
    await bot.add_cog(NewCommands(bot))
```

### è¨­å®šã®æ›´æ–°

```python
# src/config/settings.py - Add new settings
class Settings(BaseSettings):
    # ... existing settings ...

    # New feature settings
    new_feature_enabled: bool = Field(False, description="Enable new feature")
    new_feature_threshold: float = Field(0.8, description="Confidence threshold")
    new_feature_cache_ttl: int = Field(3600, description="Cache TTL in seconds")

    class Config:
        env_file = ".env"
        case_sensitive = True
```

## âš¡ Performance Optimization

### ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã¨ç›£è¦–

```python
# src/utils/profiler.py
import asyncio
import time
import functools
from typing import Callable, Any

def async_timer(func: Callable) -> Callable:
    """Decorator to time async function execution."""
    @functools.wraps(func)
    async def wrapper(*args: Any, **kwargs: Any) -> Any:
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            execution_time = time.time() - start_time
            logger.info(
                f"Function {func.__name__} completed",
                extra={
                    "execution_time": execution_time,
                    "function": func.__name__
                }
            )
            return result
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(
                f"Function {func.__name__} failed",
                extra={
                    "execution_time": execution_time,
                    "function": func.__name__,
                    "error": str(e)
                }
            )
            raise
    return wrapper

# Usage
@async_timer
async def process_message(content: str) -> ProcessingResult:
    """Process message with timing."""
    pass
```

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥

```python
# src/utils/cache.py
from typing import Any, Optional
import asyncio
from functools import wraps

class AsyncLRUCache:
    """Async LRU cache implementation."""

    def __init__(self, max_size: int = 128, ttl: int = 3600):
        self.max_size = max_size
        self.ttl = ttl
        self._cache: dict[str, tuple[Any, float]] = {}

    async def get(self, key: str) -> Optional[Any]:
        """Get item from cache."""
        if key in self._cache:
            value, timestamp = self._cache[key]
            if time.time() - timestamp < self.ttl:
                return value
            else:
                del self._cache[key]
        return None

    async def set(self, key: str, value: Any) -> None:
        """Set item in cache."""
        if len(self._cache) >= self.max_size:
            # Remove oldest item
            oldest_key = min(self._cache.keys(),
                           key=lambda k: self._cache[k][1])
            del self._cache[oldest_key]

        self._cache[key] = (value, time.time())

# Global cache instance
ai_cache = AsyncLRUCache(max_size=500, ttl=3600)

@async_timer
async def cached_ai_analysis(content: str) -> ProcessingResult:
    """AI analysis with caching."""
    cache_key = f"ai_analysis:{hash(content)}"

    # Try cache first
    cached_result = await ai_cache.get(cache_key)
    if cached_result:
        logger.debug("Cache hit for AI analysis")
        return cached_result

    # Compute result
    result = await ai_processor.analyze(content)

    # Cache result
    await ai_cache.set(cache_key, result)
    logger.debug("Cache miss for AI analysis - result cached")

    return result
```

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–

```python
# Optimize file operations
import aiofiles
from pathlib import Path

async def batch_file_operations(operations: list[tuple[Path, str]]) -> None:
    """Perform file operations in batch."""
    async def write_file(path: Path, content: str) -> None:
        async with aiofiles.open(path, "w") as f:
            await f.write(content)

    # Execute operations concurrently
    tasks = [write_file(path, content) for path, content in operations]
    await asyncio.gather(*tasks, return_exceptions=True)
```

### ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–

```python
# src/utils/memory.py
import psutil
import gc
from typing import Generator, Any

def monitor_memory() -> None:
    """Monitor memory usage."""
    process = psutil.Process()
    memory_info = process.memory_info()
    logger.info(
        "Memory usage",
        extra={
            "rss_mb": memory_info.rss / 1024 / 1024,
            "vms_mb": memory_info.vms / 1024 / 1024,
            "percent": process.memory_percent()
        }
    )

def batch_processor(items: list[Any], batch_size: int = 100) -> Generator[list[Any], None, None]:
    """Process items in batches to manage memory."""
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        yield batch
        # Force garbage collection between batches
        gc.collect()
```

---

ã“ã®é–‹ç™ºã‚¬ã‚¤ãƒ‰ã¯åŠ¹æœçš„ãª MindBridge é–‹ç™ºã®åŸºç›¤ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«å¾“ã£ã¦ã‚³ãƒ¼ãƒ‰å“è³ªã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ä¿å®ˆæ€§ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚
