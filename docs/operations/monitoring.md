# ğŸ“Š ç›£è¦–ãƒ»ãƒ­ã‚°ç®¡ç†ã‚¬ã‚¤ãƒ‰

MindBridge ã®åŒ…æ‹¬çš„ãªç›£è¦–ã€ãƒ­ã‚°ç®¡ç†ã€ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ“‹ ç›®æ¬¡

1. [ç›£è¦–æˆ¦ç•¥](#ç›£è¦–æˆ¦ç•¥)
2. [ãƒ­ã‚°ç®¡ç†](#ãƒ­ã‚°ç®¡ç†)
3. [ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†](#ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†)
4. [ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š](#ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š)
5. [ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š](#ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š)
6. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–)
7. [ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–](#ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–)
8. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ”¯æ´](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ”¯æ´)

## ğŸ¯ ç›£è¦–æˆ¦ç•¥

### ç›£è¦–ã® 4 ã¤ã®é»„é‡‘ä¿¡å·

1. **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼ˆ Latency ï¼‰**: å¿œç­”æ™‚é–“
2. **ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ï¼ˆ Traffic ï¼‰**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
3. **ã‚¨ãƒ©ãƒ¼ï¼ˆ Errors ï¼‰**: ã‚¨ãƒ©ãƒ¼ç‡
4. **ã‚µãƒãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ Saturation ï¼‰**: ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡

### ç›£è¦–éšå±¤

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Application Layer             â”‚
â”‚  â€¢ Discord Bot Status                   â”‚
â”‚  â€¢ AI å‡¦ç†ãƒ¡ãƒˆãƒªã‚¯ã‚¹                  â”‚
â”‚  â€¢ Obsidian File Operations            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Service Layer                â”‚
â”‚  â€¢ API å¿œç­”æ™‚é–“                       â”‚
â”‚  â€¢ External Service Health             â”‚
â”‚  â€¢ Database Operations                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Infrastructure Layer           â”‚
â”‚  â€¢ CPU ã€ãƒ¡ãƒ¢ãƒªã€ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡        â”‚
â”‚  â€¢ Network I/O                         â”‚
â”‚  â€¢ Container Health                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ ãƒ­ã‚°ç®¡ç†

### ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š

```python
# src/utils/logger.py
import structlog
import logging
from enum import Enum

class LogLevel(Enum):
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

# æ§‹é€ åŒ–ãƒ­ã‚°ã®è¨­å®š
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="ISO"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)
```

### ãƒ­ã‚°å‡ºåŠ›ä¾‹

**æ­£å¸¸å‡¦ç†:**
```json
{
  "timestamp": "2025-08-17T10:30:15.123Z",
  "level": "info",
  "event": "message_processed",
  "user_id": "123456789012345678",
  "channel_id": "987654321098765432",
  "processing_time": 1.234,
  "ai_tokens_used": 150,
  "obsidian_file": "00_Inbox/2025-08-17-user-memo.md"
}
```

**ã‚¨ãƒ©ãƒ¼å‡¦ç†:**
```json
{
  "timestamp": "2025-08-17T10:31:20.456Z",
  "level": "error",
  "event": "ai_processing_failed",
  "error": "APIError",
  "error_message": "Rate limit exceeded",
  "user_id": "123456789012345678",
  "retry_count": 2,
  "max_retries": 3,
  "stack_trace": "..."
}
```

### Google Cloud Logging è¨­å®š

```yaml
# logging.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: logging-config
data:
  log_config.json: |
    {
      "version": 1,
      "disable_existing_loggers": false,
      "formatters": {
        "json": {
          "format": "%(asctime) s %(name) s %(levelname) s %(message) s",
          "class": "pythonjsonlogger.jsonlogger.JsonFormatter"
        }
      },
      "handlers": {
        "console": {
          "class": "logging.StreamHandler",
          "level": "INFO",
          "formatter": "json",
          "stream": "ext://sys.stdout"
        },
        "file": {
          "class": "logging.handlers.RotatingFileHandler",
          "level": "DEBUG",
          "formatter": "json",
          "filename": "/app/logs/bot.log",
          "maxBytes": 10485760,
          "backupCount": 5
        }
      },
      "loggers": {
        "discord": {
          "level": "WARNING"
        },
        "src": {
          "level": "DEBUG"
        }
      },
      "root": {
        "level": "INFO",
        "handlers": ["console", "file"]
      }
    }
```

### ãƒ­ã‚°é›†ç´„è¨­å®š

```bash
# Google Cloud Logging ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
# /etc/google-fluentd/config.d/discord-bot.conf
<source>
  @type tail
  path /app/logs/bot.log
  pos_file /var/lib/google-fluentd/pos/discord-bot.log.pos
  tag discord.bot
  format json
  time_key timestamp
  time_format %Y-%m-%dT%H:%M:%S.%L%z
</source>

<filter discord.bot>
  @type record_transformer
  <record>
    service_name mindbridge
    environment ${ENV}
  </record>
</filter>

<match discord.bot>
  @type google_cloud
  project_id YOUR_PROJECT_ID
  zone YOUR_ZONE
  vm_id YOUR_VM_ID
  vm_name YOUR_VM_NAME
</match>
```

## ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

### ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©

```python
# src/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time
from functools import wraps

# ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
MESSAGES_PROCESSED = Counter(
    'discord_messages_processed_total',
    'Total number of processed Discord messages',
    ['channel', 'status']
)

AI_REQUESTS = Counter(
    'ai_requests_total',
    'Total number of AI API requests',
    ['api', 'status']
)

OBSIDIAN_FILES_CREATED = Counter(
    'obsidian_files_created_total',
    'Total number of Obsidian files created',
    ['folder']
)

# ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
PROCESSING_TIME = Histogram(
    'message_processing_duration_seconds',
    'Time spent processing messages',
    ['operation']
)

AI_RESPONSE_TIME = Histogram(
    'ai_response_duration_seconds',
    'AI API response time',
    ['api']
)

# ã‚²ãƒ¼ã‚¸
ACTIVE_CONNECTIONS = Gauge(
    'discord_active_connections',
    'Number of active Discord connections'
)

MEMORY_USAGE = Gauge(
    'process_memory_usage_bytes',
    'Process memory usage in bytes'
)

# ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼
def track_processing_time(operation: str):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = await func(*args, **kwargs)
                PROCESSING_TIME.labels(operation=operation).observe(
                    time.time() - start_time
                )
                return result
            except Exception as e:
                PROCESSING_TIME.labels(operation=f"{operation}_error").observe(
                    time.time() - start_time
                )
                raise
        return wrapper
    return decorator

# ä½¿ç”¨ä¾‹
@track_processing_time("ai_analysis")
async def analyze_message(self, content: str):
    # AI åˆ†æå‡¦ç†
    pass
```

### ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
# src/monitoring/system_metrics.py
import psutil
import asyncio
from typing import Dict, Any

class SystemMetrics:
    def __init__(self):
        self.process = psutil.Process()

    async def get_metrics(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—."""
        cpu_percent = self.process.cpu_percent()
        memory_info = self.process.memory_info()
        disk_usage = psutil.disk_usage('/')

        return {
            "cpu": {
                "percent": cpu_percent,
                "count": psutil.cpu_count()
            },
            "memory": {
                "rss": memory_info.rss,
                "vms": memory_info.vms,
                "percent": self.process.memory_percent(),
                "available": psutil.virtual_memory().available
            },
            "disk": {
                "total": disk_usage.total,
                "used": disk_usage.used,
                "free": disk_usage.free,
                "percent": disk_usage.percent
            },
            "network": {
                "connections": len(self.process.connections())
            }
        }

    async def update_prometheus_metrics(self):
        """Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ›´æ–°."""
        metrics = await self.get_metrics()

        MEMORY_USAGE.set(metrics["memory"]["rss"])
        ACTIVE_CONNECTIONS.set(metrics["network"]["connections"])
```

### Discord ç‰¹æœ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
# src/monitoring/discord_metrics.py
class DiscordMetrics:
    def __init__(self, bot_client):
        self.bot = bot_client

    async def collect_discord_metrics(self):
        """Discord é–¢é€£ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†."""
        if self.bot.is_ready():
            guild_count = len(self.bot.guilds)
            user_count = sum(guild.member_count for guild in self.bot.guilds)
            channel_count = sum(len(guild.channels) for guild in self.bot.guilds)

            # WebSocket latency
            latency = round(self.bot.latency * 1000, 2)

            return {
                "guilds": guild_count,
                "users": user_count,
                "channels": channel_count,
                "latency_ms": latency,
                "shards": len(self.bot.shards) if self.bot.shards else 1
            }
        return {}
```

## ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

### Cloud Monitoring ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒªã‚·ãƒ¼

```yaml
# alert-policies.yaml
displayName: "Discord Bot Critical Alerts"
conditions:
  # ã‚¨ãƒ©ãƒ¼ç‡ã‚¢ãƒ©ãƒ¼ãƒˆ
  - displayName: "High Error Rate"
    conditionThreshold:
      filter: |
        resource.type="cloud_run_revision"
        resource.labels.service_name="mindbridge"
        severity>=ERROR
      comparison: COMPARISON_GREATER_THAN
      thresholdValue: 10
      duration: 300s
      aggregations:
        - alignmentPeriod: 60s
          perSeriesAligner: ALIGN_RATE
          crossSeriesReducer: REDUCE_SUM

  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã‚¢ãƒ©ãƒ¼ãƒˆ
  - displayName: "High Response Time"
    conditionThreshold:
      filter: |
        metric.type="run.googleapis.com/request_latencies"
        resource.labels.service_name="mindbridge"
      comparison: COMPARISON_GREATER_THAN
      thresholdValue: 5000  # 5 ç§’
      duration: 180s
      aggregations:
        - alignmentPeriod: 60s
          perSeriesAligner: ALIGN_PERCENTILE_95

  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã‚¢ãƒ©ãƒ¼ãƒˆ
  - displayName: "High Memory Usage"
    conditionThreshold:
      filter: |
        metric.type="run.googleapis.com/container/memory/utilizations"
        resource.labels.service_name="mindbridge"
      comparison: COMPARISON_GREATER_THAN
      thresholdValue: 0.8  # 80%
      duration: 300s

# é€šçŸ¥è¨­å®š
notificationChannels:
  - projects/PROJECT_ID/notificationChannels/EMAIL_CHANNEL
  - projects/PROJECT_ID/notificationChannels/DISCORD_WEBHOOK

alertStrategy:
  autoClose: 604800s  # 7 æ—¥å¾Œã«è‡ªå‹•ã‚¯ãƒ­ãƒ¼ã‚º

documentation:
  content: |
    Discord Obsidian Memo Bot ã®ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¢ãƒ©ãƒ¼ãƒˆ

    ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:
    1. Cloud Run ãƒ­ã‚°ã‚’ç¢ºèª
    2. /status ã‚³ãƒãƒ³ãƒ‰ã§ Bot çŠ¶æ…‹ç¢ºèª
    3. å¿…è¦ã«å¿œã˜ã¦ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
  mimeType: text/markdown
```

### Discord Webhook ã‚¢ãƒ©ãƒ¼ãƒˆ

```python
# src/monitoring/alerts.py
import aiohttp
import json
from datetime import datetime
from typing import Dict, Any

class DiscordAlerts:
    def __init__(self, webhook_url: str):
        self.webhook_url = webhook_url

    async def send_alert(
        self,
        level: str,
        title: str,
        description: str,
        fields: Dict[str, Any] = None
    ):
        """Discord ã«ã‚¢ãƒ©ãƒ¼ãƒˆã‚’é€ä¿¡."""

        color_map = {
            "critical": 0xFF0000,  # èµ¤
            "warning": 0xFFA500,   # ã‚ªãƒ¬ãƒ³ã‚¸
            "info": 0x00FF00,      # ç·‘
            "resolved": 0x0080FF   # é’
        }

        embed = {
            "title": f"ğŸš¨ {title}",
            "description": description,
            "color": color_map.get(level, 0x808080),
            "timestamp": datetime.utcnow().isoformat(),
            "fields": []
        }

        if fields:
            for key, value in fields.items():
                embed["fields"].append({
                    "name": key,
                    "value": str(value),
                    "inline": True
                })

        payload = {
            "embeds": [embed],
            "username": "Monitoring Bot"
        }

        async with aiohttp.ClientSession() as session:
            async with session.post(
                self.webhook_url,
                json=payload,
                headers={"Content-Type": "application/json"}
            ) as response:
                if response.status != 204:
                    logger.error(
                        "Failed to send Discord alert",
                        status=response.status,
                        response=await response.text()
                    )

# ä½¿ç”¨ä¾‹
alerts = DiscordAlerts(webhook_url)

await alerts.send_alert(
    level="critical",
    title="High Error Rate Detected",
    description="Error rate exceeded 10% in the last 5 minutes",
    fields={
        "Error Count": 15,
        "Total Requests": 120,
        "Service": "mindbridge",
        "Region": "asia-northeast1"
    }
)
```

## ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š

### Grafana ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š

```json
{
  "dashboard": {
    "title": "Discord Obsidian Memo Bot",
    "panels": [
      {
        "title": "Message Processing Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(discord_messages_processed_total[5m])",
            "legendFormat": "{{channel}} - {{status}}"
          }
        ]
      },
      {
        "title": "AI Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(ai_response_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(ai_response_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          }
        ]
      },
      {
        "title": "System Resources",
        "type": "graph",
        "targets": [
          {
            "expr": "process_memory_usage_bytes",
            "legendFormat": "Memory Usage"
          },
          {
            "expr": "rate(process_cpu_usage_total[5m])",
            "legendFormat": "CPU Usage"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(discord_messages_processed_total{status=\"error\"}[5m]) / rate(discord_messages_processed_total[5m]) * 100",
            "legendFormat": "Error Rate %"
          }
        ]
      }
    ]
  }
}
```

### Cloud Monitoring ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

```yaml
# cloud-monitoring-dashboard.yaml
displayName: "Discord Obsidian Memo Bot Dashboard"
mosaicLayout:
  tiles:
    # Cloud Run ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    - width: 6
      height: 4
      xPos: 0
      yPos: 0
      widget:
        title: "Request Count"
        xyChart:
          dataSets:
            - timeSeriesQuery:
                timeSeriesFilter:
                  filter: |
                    metric.type="run.googleapis.com/request_count"
                    resource.type="cloud_run_revision"
                  aggregation:
                    alignmentPeriod: 60s
                    perSeriesAligner: ALIGN_RATE

    # CPU ä½¿ç”¨ç‡
    - width: 6
      height: 4
      xPos: 6
      yPos: 0
      widget:
        title: "CPU Utilization"
        xyChart:
          dataSets:
            - timeSeriesQuery:
                timeSeriesFilter:
                  filter: |
                    metric.type="run.googleapis.com/container/cpu/utilizations"
                    resource.type="cloud_run_revision"

    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
    - width: 6
      height: 4
      xPos: 0
      yPos: 4
      widget:
        title: "Memory Utilization"
        xyChart:
          dataSets:
            - timeSeriesQuery:
                timeSeriesFilter:
                  filter: |
                    metric.type="run.googleapis.com/container/memory/utilizations"
                    resource.type="cloud_run_revision"

    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
    - width: 6
      height: 4
      xPos: 6
      yPos: 4
      widget:
        title: "Error Logs"
        logsPanel:
          filter: |
            resource.type="cloud_run_revision"
            resource.labels.service_name="mindbridge"
            severity>=ERROR
```

## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

```python
# src/monitoring/performance.py
import asyncio
import time
from collections import defaultdict, deque
from typing import Dict, List

class PerformanceMonitor:
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.metrics = defaultdict(lambda: deque(maxlen=window_size))

    def record_timing(self, operation: str, duration: float):
        """å‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²."""
        self.metrics[f"{operation}_duration"].append(duration)

    def record_counter(self, metric: str, value: int = 1):
        """ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’è¨˜éŒ²."""
        self.metrics[metric].append(value)

    def get_stats(self, metric: str) -> Dict[str, float]:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—."""
        values = list(self.metrics[metric])
        if not values:
            return {}

        return {
            "count": len(values),
            "avg": sum(values) / len(values),
            "min": min(values),
            "max": max(values),
            "p95": sorted(values)[int(len(values) * 0.95)] if values else 0,
            "p99": sorted(values)[int(len(values) * 0.99)] if values else 0
        }

    async def get_performance_report(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ."""
        report = {}

        for metric_name in self.metrics:
            if metric_name.endswith('_duration'):
                operation = metric_name.replace('_duration', '')
                report[operation] = self.get_stats(metric_name)

        return report

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
perf_monitor = PerformanceMonitor()

# ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼
def monitor_performance(operation: str):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = await func(*args, **kwargs)
                duration = time.time() - start_time
                perf_monitor.record_timing(operation, duration)
                perf_monitor.record_counter(f"{operation}_success")
                return result
            except Exception as e:
                duration = time.time() - start_time
                perf_monitor.record_timing(f"{operation}_error", duration)
                perf_monitor.record_counter(f"{operation}_error")
                raise
        return wrapper
    return decorator
```

### ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ç›£è¦–

```python
# src/monitoring/resource_monitor.py
import psutil
import asyncio
from datetime import datetime, timedelta

class ResourceMonitor:
    def __init__(self):
        self.process = psutil.Process()
        self.baseline_memory = self.process.memory_info().rss
        self.memory_samples = deque(maxlen=100)
        self.cpu_samples = deque(maxlen=100)

    async def collect_samples(self):
        """ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚µãƒ³ãƒ—ãƒ«ã‚’åé›†."""
        while True:
            try:
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
                memory_info = self.process.memory_info()
                memory_usage = memory_info.rss / 1024 / 1024  # MB
                self.memory_samples.append({
                    "timestamp": datetime.utcnow(),
                    "usage_mb": memory_usage,
                    "growth_mb": memory_usage - (self.baseline_memory / 1024 / 1024)
                })

                # CPU ä½¿ç”¨ç‡
                cpu_percent = self.process.cpu_percent()
                self.cpu_samples.append({
                    "timestamp": datetime.utcnow(),
                    "usage_percent": cpu_percent
                })

                # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º
                if len(self.memory_samples) >= 10:
                    recent_avg = sum(s["usage_mb"] for s in list(self.memory_samples)[-10:]) / 10
                    older_avg = sum(s["usage_mb"] for s in list(self.memory_samples)[-50:-40]) / 10

                    if recent_avg > older_avg * 1.5:  # 50% ä»¥ä¸Šã®å¢—åŠ 
                        logger.warning(
                            "Potential memory leak detected",
                            recent_avg=recent_avg,
                            older_avg=older_avg,
                            growth_rate=(recent_avg / older_avg - 1) * 100
                        )

                await asyncio.sleep(30)  # 30 ç§’é–“éš”

            except Exception as e:
                logger.error("Resource monitoring failed", error=str(e))
                await asyncio.sleep(60)

    def get_resource_summary(self) -> Dict[str, Any]:
        """ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚µãƒãƒªãƒ¼ã‚’å–å¾—."""
        if not self.memory_samples:
            return {}

        recent_memory = list(self.memory_samples)[-10:]
        recent_cpu = list(self.cpu_samples)[-10:]

        return {
            "memory": {
                "current_mb": recent_memory[-1]["usage_mb"],
                "avg_mb": sum(s["usage_mb"] for s in recent_memory) / len(recent_memory),
                "max_mb": max(s["usage_mb"] for s in recent_memory),
                "growth_mb": recent_memory[-1]["growth_mb"]
            },
            "cpu": {
                "current_percent": recent_cpu[-1]["usage_percent"],
                "avg_percent": sum(s["usage_percent"] for s in recent_cpu) / len(recent_cpu),
                "max_percent": max(s["usage_percent"] for s in recent_cpu)
            }
        }
```

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡º

```python
# src/monitoring/security_monitor.py
import re
from datetime import datetime, timedelta
from collections import defaultdict

class SecurityMonitor:
    def __init__(self):
        self.failed_attempts = defaultdict(list)
        self.suspicious_patterns = [
            r'(?i)(union|select|drop|insert|delete|update|exec)',  # SQL injection
            r'(?i)(<script|javascript:|onload=)',  # XSS
            r'(?i)(\.\.\/|\.\.\\)',  # Path traversal
        ]

    async def log_security_event(
        self,
        event_type: str,
        user_id: str,
        details: Dict[str, Any],
        severity: str = "info"
    ):
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ­ã‚°è¨˜éŒ²."""
        event = {
            "timestamp": datetime.utcnow().isoformat(),
            "event_type": event_type,
            "user_id": user_id,
            "severity": severity,
            "details": details
        }

        # æ§‹é€ åŒ–ãƒ­ã‚°ã¨ã—ã¦å‡ºåŠ›
        logger.bind(**event).info("Security event logged")

        # é‡è¦åº¦ãŒé«˜ã„å ´åˆã¯ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
        if severity in ["warning", "error", "critical"]:
            await self.send_security_alert(event)

    async def analyze_message_content(self, user_id: str, content: str):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‚’ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†æ."""
        suspicious_findings = []

        for pattern in self.suspicious_patterns:
            if re.search(pattern, content):
                suspicious_findings.append({
                    "pattern": pattern,
                    "matched_text": re.search(pattern, content).group()
                })

        if suspicious_findings:
            await self.log_security_event(
                event_type="suspicious_content",
                user_id=user_id,
                details={
                    "content_length": len(content),
                    "findings": suspicious_findings
                },
                severity="warning"
            )

    async def detect_rate_limit_abuse(self, user_id: str):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ¿«ç”¨ã‚’æ¤œå‡º."""
        now = datetime.utcnow()
        cutoff = now - timedelta(minutes=5)

        # 5 åˆ†é–“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’è¨ˆç®—
        recent_requests = [
            req for req in self.failed_attempts[user_id]
            if req > cutoff
        ]

        if len(recent_requests) > 20:  # 5 åˆ†é–“ã§ 20 å›ä»¥ä¸Š
            await self.log_security_event(
                event_type="rate_limit_abuse",
                user_id=user_id,
                details={
                    "request_count": len(recent_requests),
                    "time_window": "5_minutes"
                },
                severity="warning"
            )
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ”¯æ´

### è¨ºæ–­ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

```python
# src/monitoring/diagnostics.py
from fastapi import FastAPI
from typing import Dict, Any

class DiagnosticsAPI:
    def __init__(self, app: FastAPI, bot_client):
        self.app = app
        self.bot = bot_client
        self.setup_routes()

    def setup_routes(self):
        @self.app.get("/health")
        async def health_check():
            return {
                "status": "healthy",
                "timestamp": datetime.utcnow().isoformat(),
                "version": "1.0.0",
                "discord_ready": self.bot.is_ready() if self.bot else False
            }

        @self.app.get("/metrics")
        async def get_metrics():
            return await self.collect_all_metrics()

        @self.app.get("/debug/config")
        async def debug_config():
            # æ©Ÿå¯†æƒ…å ±ã‚’é™¤ã„ãŸè¨­å®šæƒ…å ±
            return {
                "environment": os.getenv("ENVIRONMENT"),
                "log_level": os.getenv("LOG_LEVEL"),
                "obsidian_vault_configured": bool(os.getenv("OBSIDIAN_VAULT_PATH")),
                "channels_configured": self.count_configured_channels()
            }

        @self.app.get("/debug/discord")
        async def debug_discord():
            if not self.bot or not self.bot.is_ready():
                return {"status": "not_ready"}

            return {
                "status": "ready",
                "latency": round(self.bot.latency * 1000, 2),
                "guilds": len(self.bot.guilds),
                "users": sum(guild.member_count for guild in self.bot.guilds),
                "shards": len(self.bot.shards) if self.bot.shards else 1
            }

    async def collect_all_metrics(self) -> Dict[str, Any]:
        """å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†."""
        return {
            "system": await system_metrics.get_metrics(),
            "performance": await perf_monitor.get_performance_report(),
            "resources": resource_monitor.get_resource_summary(),
            "discord": await discord_metrics.collect_discord_metrics()
        }
```

### è‡ªå‹•è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# scripts/diagnose.sh

echo "ğŸ” Discord Obsidian Memo Bot è¨ºæ–­ãƒ„ãƒ¼ãƒ«"
echo "========================================"

# åŸºæœ¬ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo "1. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"
HEALTH_RESPONSE=$(curl -s http://localhost:8080/health)
echo "Status: $(echo $HEALTH_RESPONSE | jq -r '.status')"
echo "Discord Ready: $(echo $HEALTH_RESPONSE | jq -r '.discord_ready')"

# ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
echo -e "\n2. ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹"
METRICS=$(curl -s http://localhost:8080/metrics)
echo "Memory Usage: $(echo $METRICS | jq -r '.system.memory.percent')%"
echo "CPU Usage: $(echo $METRICS | jq -r '.system.cpu.percent')%"
echo "Disk Usage: $(echo $METRICS | jq -r '.system.disk.percent')%"

# Discord çŠ¶æ…‹
echo -e "\n3. Discord çŠ¶æ…‹"
DISCORD_DEBUG=$(curl -s http://localhost:8080/debug/discord)
echo "Latency: $(echo $DISCORD_DEBUG | jq -r '.latency') ms"
echo "Guilds: $(echo $DISCORD_DEBUG | jq -r '.guilds')"

# æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼
echo -e "\n4. æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°"
tail -n 20 logs/bot.log | jq -r 'select(.level == "error") | "\(.timestamp) - \(.event): \(.error_message)"' | tail -5

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
echo -e "\n5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ"
PERF=$(echo $METRICS | jq -r '.performance')
echo "Message Processing Avg: $(echo $PERF | jq -r '.message_processing.avg // "N/A"') s"
echo "AI Response Avg: $(echo $PERF | jq -r '.ai_analysis.avg // "N/A"') s"

echo -e "\n âœ… è¨ºæ–­å®Œäº†"
```

## ğŸ“‹ ç›£è¦–ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### æ—¥æ¬¡ãƒã‚§ãƒƒã‚¯
- [ ] ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèª
- [ ] ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç¢ºèª
- [ ] ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã®ç¢ºèª
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç¢ºèª

### é€±æ¬¡ãƒã‚§ãƒƒã‚¯
- [ ] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®å…¨ä½“ç¢ºèª
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã®è¦‹ç›´ã—
- [ ] ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ç¢ºèª

### æœˆæ¬¡ãƒã‚§ãƒƒã‚¯
- [ ] ç›£è¦–è¨­å®šã®æœ€é©åŒ–
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆã—ãã„å€¤ã®èª¿æ•´
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã®åˆ†æ
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°ã®åˆ†æ

---

ã“ã®ç›£è¦–ãƒ»ãƒ­ã‚°ç®¡ç†ã‚¬ã‚¤ãƒ‰ã‚’æ´»ç”¨ã—ã¦ã€ MindBridge ã®å®‰å®šç¨¼åƒã‚’ç¢ºä¿ã—ã¦ãã ã•ã„ã€‚å•é¡Œã®æ—©æœŸç™ºè¦‹ã¨è¿…é€Ÿãªå¯¾å¿œã«ã‚ˆã‚Šã€ã‚µãƒ¼ãƒ“ã‚¹å“è³ªã‚’ç¶­æŒã§ãã¾ã™ã€‚
